{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from rdkit import Chem\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import load_dataset_df, fp_generator\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn import model_selection, svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p_np']\n",
      "2050 1 : 1.3\n"
     ]
    }
   ],
   "source": [
    "files = ['tox21.csv','sider.csv', 'BBBP.csv']\n",
    "dt_file = files[2]\n",
    "\n",
    "df, targets = load_dataset_df(filename=dt_file)\n",
    "print(targets)\n",
    "\n",
    "\n",
    "target_name = targets[0]\n",
    "df = df[[target_name, 'smiles']].dropna()\n",
    "print(df[target_name].size,\"1 :\", np.round(df[target_name].size/df[target_name].sum(), 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_np\n",
      "1567\n",
      "2050\n"
     ]
    }
   ],
   "source": [
    "print(target_name)\n",
    "print(df[target_name].sum())\n",
    "print(df[target_name].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMILE to Fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDKit - 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:14:58] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "[22:14:58] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:14:58] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "[22:14:58] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:14:59] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:14:59] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:14:59] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:14:59] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:14:59] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:14:59] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "[22:15:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:00] Explicit valence for atom # 11 N, 4, is greater than permitted\n",
      "[22:15:00] Explicit valence for atom # 12 N, 4, is greater than permitted\n",
      "[22:15:00] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[22:15:00] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[22:15:00] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[22:15:00] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[22:15:00] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[22:15:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:00] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[22:15:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:02] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:02] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:02] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:02] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:02] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:02] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:02] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:03] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:03] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:03] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:03] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:03] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:03] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:03] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:03] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:15:05] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "fp_types = [['morgan', 1024], ['maccs', 167], ['RDKit', 1024]]\n",
    "fp_type, num_bits = fp_types[2]\n",
    "print(fp_type, '-', num_bits)\n",
    "num_rows = len(df)\n",
    "fp_array = np.zeros((num_rows, num_bits))\n",
    "target_array = np.zeros((num_rows, 1))\n",
    "i = 0\n",
    "\n",
    "img = None\n",
    "# Smile to Fingerprint of size {num_bits}\n",
    "fp_gen = fp_generator(fp_type)\n",
    "for idx, row in df.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['smiles'])\n",
    "    #TODO: sanitize molecules to remove the warnings (?)\n",
    "    \n",
    "    if mol is not None:\n",
    "        fingerprint = fp_gen(mol)\n",
    "\n",
    "        fp_array[i] = np.array(fingerprint)\n",
    "        target_array[i] = row[target_name]\n",
    "        i += 1\n",
    "target_array = target_array.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:\n",
      "1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\knsve\\Desktop\\MEI\\Tese\\torch\\pt_venv\\Lib\\site-packages\\threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Best Parameters: {'weights': 'distance', 'n_neighbors': 8, 'metric': 'manhattan'}\n",
      "KNN Best Score: 0.8710977407229674\n",
      "2/30\n",
      "3/30\n",
      "4/30\n",
      "5/30\n",
      "6/30\n",
      "7/30\n",
      "8/30\n",
      "9/30\n",
      "10/30\n",
      "11/30\n",
      "12/30\n",
      "13/30\n",
      "14/30\n",
      "15/30\n",
      "16/30\n",
      "17/30\n",
      "18/30\n",
      "19/30\n",
      "20/30\n",
      "21/30\n",
      "22/30\n",
      "23/30\n",
      "24/30\n",
      "25/30\n",
      "26/30\n",
      "27/30\n",
      "28/30\n",
      "29/30\n",
      "30/30\n"
     ]
    }
   ],
   "source": [
    "#Metrics ---- roc  acc f1  prs sns sps\n",
    "svm_metrics = [[], [], [], [], [], []]\n",
    "rf_metrics  = [[], [], [], [], [], []]\n",
    "knn_metrics = [[], [], [], [], [], []]\n",
    "xgb_metrics = [[], [], [], [], [], []]\n",
    "mlp_metrics = [[], [], [], [], [], []]\n",
    "\n",
    "knn_param_dist = {\n",
    "        'n_neighbors': range(1, 20),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "    }\n",
    "knn_best_params = []\n",
    "\n",
    "print(\"Iterations:\")\n",
    "for i in range(2, 32):\n",
    "    print(str(i - 1) + \"/30\")\n",
    "    seed = i - 1\n",
    "    random.seed(seed)\n",
    "    \n",
    "    Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(fp_array,target_array, test_size=0.3, shuffle=True, random_state=seed)\n",
    "\n",
    "    class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(Train_Y), y=Train_Y)\n",
    "    #class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "    class_weights_dict = \"balanced\"\n",
    "\n",
    "\n",
    "    #################### SVM ####################\n",
    "\n",
    "    SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto', class_weight=class_weights_dict, random_state=seed)\n",
    "\n",
    "    SVM.fit(Train_X,Train_Y)\n",
    "\n",
    "    predictions_SVM = SVM.predict(Test_X)\n",
    "\n",
    "    svm_metrics[0].append(roc_auc_score(Test_Y, predictions_SVM))\n",
    "    svm_metrics[1].append(accuracy_score(Test_Y, predictions_SVM))\n",
    "    svm_metrics[2].append(f1_score(Test_Y, predictions_SVM))\n",
    "    svm_metrics[3].append(precision_score(Test_Y, predictions_SVM))\n",
    "    svm_metrics[4].append(recall_score(Test_Y, predictions_SVM))\n",
    "    tn, fp, fn, tp = confusion_matrix(Test_Y, predictions_SVM).ravel()\n",
    "    sp = tn/(tn+fp)\n",
    "    svm_metrics[5].append(sp)\n",
    "\n",
    "    #################### RF ####################\n",
    "\n",
    "    RF = RandomForestClassifier(max_depth=10, n_estimators=100, class_weight=class_weights_dict, random_state=seed)\n",
    "\n",
    "    RF.fit(Train_X,Train_Y)\n",
    "\n",
    "    predictions_RF = RF.predict(Test_X)\n",
    "\n",
    "    rf_metrics[0].append(roc_auc_score(Test_Y, predictions_RF))\n",
    "    rf_metrics[1].append(accuracy_score(Test_Y, predictions_RF))\n",
    "    rf_metrics[2].append(f1_score(Test_Y, predictions_RF))\n",
    "    rf_metrics[3].append(precision_score(Test_Y, predictions_RF))\n",
    "    rf_metrics[4].append(recall_score(Test_Y, predictions_RF))\n",
    "    tn, fp, fn, tp = confusion_matrix(Test_Y, predictions_RF).ravel()\n",
    "    sp = tn/(tn+fp)\n",
    "    rf_metrics[5].append(sp)\n",
    "\n",
    "    #################### XGB ####################\n",
    "    #pos_weight = sum(Train_Y == 0) / sum(Train_Y == 1)\n",
    "    pos_weight=1\n",
    "    XGB = XGBClassifier(objective=\"binary:logistic\",learning_rate=0.1,max_depth=6,n_estimators=100,scale_pos_weight=pos_weight)\n",
    "\n",
    "    XGB.fit(Train_X,Train_Y)\n",
    "\n",
    "    predictions_XGB = XGB.predict(Test_X)\n",
    "\n",
    "    xgb_metrics[0].append(roc_auc_score(Test_Y, predictions_XGB))\n",
    "    xgb_metrics[1].append(accuracy_score(Test_Y, predictions_XGB))\n",
    "    xgb_metrics[2].append(f1_score(Test_Y, predictions_XGB))\n",
    "    xgb_metrics[3].append(precision_score(Test_Y, predictions_XGB))\n",
    "    xgb_metrics[4].append(recall_score(Test_Y, predictions_XGB))\n",
    "    tn, fp, fn, tp = confusion_matrix(Test_Y, predictions_XGB).ravel()\n",
    "    sp = tn/(tn+fp)\n",
    "    xgb_metrics[5].append(sp)\n",
    "\n",
    "    #################### KNN ####################\n",
    "\n",
    "    # Randomized search for knn\n",
    "    \n",
    "    if i == 2:\n",
    "        KNN = KNeighborsClassifier()\n",
    "\n",
    "        #Randomized Search\n",
    "        random_search = RandomizedSearchCV(KNN, knn_param_dist, n_iter=20, cv=5, scoring='roc_auc', random_state=42)\n",
    "        random_search.fit(Train_X, Train_Y)\n",
    "\n",
    "        print(\"KNN Best Parameters:\", random_search.best_params_)\n",
    "        print(\"KNN Best Score:\", random_search.best_score_)\n",
    "\n",
    "        knn_best_params = random_search.best_params_\n",
    "\n",
    "    else:\n",
    "        KNN = KNeighborsClassifier(\n",
    "            n_neighbors=knn_best_params['n_neighbors'],\n",
    "            weights=knn_best_params['weights'],\n",
    "            metric=knn_best_params['metric'])\n",
    "\n",
    "\n",
    "    KNN.fit(Train_X,Train_Y)\n",
    "\n",
    "    predictions_KNN = KNN.predict(Test_X)\n",
    "\n",
    "    knn_metrics[0].append(roc_auc_score(Test_Y, predictions_KNN))\n",
    "    knn_metrics[1].append(accuracy_score(Test_Y, predictions_KNN))\n",
    "    knn_metrics[2].append(f1_score(Test_Y, predictions_KNN))\n",
    "    knn_metrics[3].append(precision_score(Test_Y, predictions_KNN))\n",
    "    knn_metrics[4].append(recall_score(Test_Y, predictions_KNN))\n",
    "    tn, fp, fn, tp = confusion_matrix(Test_Y, predictions_KNN).ravel()\n",
    "    sp = tn/(tn+fp)\n",
    "    knn_metrics[5].append(sp)\n",
    "\n",
    "    #################### MLP ####################\n",
    "\n",
    "    #sample_weight = np.array([class_weights[cls] for cls in Train_Y])\n",
    "    #sample_weight = None\n",
    "    MLP =  MLPClassifier(hidden_layer_sizes=(num_bits), activation='relu', solver='adam', max_iter=200)\n",
    "    MLP.fit(Train_X, Train_Y)\n",
    "    predictions_MLP = MLP.predict(Test_X)\n",
    "\n",
    "    mlp_metrics[0].append(roc_auc_score(Test_Y, predictions_MLP))\n",
    "    mlp_metrics[1].append(accuracy_score(Test_Y, predictions_MLP))\n",
    "    mlp_metrics[2].append(f1_score(Test_Y, predictions_MLP))\n",
    "    mlp_metrics[3].append(precision_score(Test_Y, predictions_MLP))\n",
    "    mlp_metrics[4].append(recall_score(Test_Y, predictions_MLP))\n",
    "    tn, fp, fn, tp = confusion_matrix(Test_Y, predictions_MLP).ravel()\n",
    "    sp = tn/(tn+fp)\n",
    "    mlp_metrics[5].append(sp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results\\updated\\weighted\\ml_baselines_BBBP_RDKit_p_np.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics = [svm_metrics, rf_metrics, xgb_metrics, knn_metrics, mlp_metrics]\n",
    "metrics_np = np.zeros((len(metrics), 12))\n",
    "\n",
    "for i, clf in enumerate(metrics):\n",
    "    metrics_np[i, 0::2] = np.round([np.mean(metric) for metric in clf], 3)\n",
    "    metrics_np[i, 1::2] = np.round([np.std(metric) for metric in clf], 3)    \n",
    "\n",
    "\n",
    "metric_names = ['AUC', 'Accuracy', 'F1 Score', 'Precision', 'Sensitivity', 'Specificity']\n",
    "\n",
    "columns = []\n",
    "clfs = [\"SVM\", \"RF\",\"XGB\", \"KNN\", \"MLP\"]\n",
    "for name in metric_names:\n",
    "    columns.extend([f'Mean {name}', f'Std {name}'])\n",
    "\n",
    "df_clfs = pd.DataFrame(clfs, columns=[\"Classifier\"])\n",
    "df_metrics = pd.DataFrame(metrics_np, columns=columns)\n",
    "df = pd.concat([df_clfs, df_metrics], axis=1)\n",
    "\n",
    "filename = f\"results\\\\updated\\\\weighted\\\\ml_baselines_{dt_file.strip('.csv')}_{fp_type}_{target_name}.csv\"\n",
    "df.to_csv(filename, index=False)\n",
    "print(filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
