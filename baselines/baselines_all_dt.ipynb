{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "No normalization for NumAmideBonds. Feature removed!\n",
      "No normalization for NumAtomStereoCenters. Feature removed!\n",
      "No normalization for NumBridgeheadAtoms. Feature removed!\n",
      "No normalization for NumHeterocycles. Feature removed!\n",
      "No normalization for NumSpiroAtoms. Feature removed!\n",
      "No normalization for NumUnspecifiedAtomStereoCenters. Feature removed!\n",
      "No normalization for Phi. Feature removed!\n",
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (c:\\Users\\knsve\\Desktop\\MEI\\Tese\\torch\\snn_venv\\lib\\site-packages\\deepchem\\models\\torch_models\\__init__.py)\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (c:\\Users\\knsve\\Desktop\\MEI\\Tese\\torch\\snn_venv\\lib\\site-packages\\deepchem\\models\\torch_models\\__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "Skipped loading some PyTorch models, missing a dependency. No module named 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from rdkit import Chem\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import load_dataset_df, smile_to_fp, data_splitter\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn import model_selection, svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD',\n",
      "       'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "files = ['tox21.csv','sider.csv', 'BBBP.csv']\n",
    "dt_file = files[0]\n",
    "dirname = dt_file.removesuffix('.csv')\n",
    "\n",
    "df, targets = load_dataset_df(filename=dt_file)\n",
    "print(targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR-ARE\n",
      "942.0\n",
      "5832\n"
     ]
    }
   ],
   "source": [
    "if dirname == 'tox21':\n",
    "    # SR-ARE\n",
    "    target_name = targets[7]\n",
    "elif dirname == 'sider':\n",
    "    target_name = targets[0]\n",
    "else:\n",
    "    target_name = targets[0]\n",
    "    \n",
    "df = df[[target_name, 'smiles']].dropna()\n",
    "\n",
    "print(target_name)\n",
    "print(df[target_name].sum())\n",
    "print(df[target_name].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMILE to Fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDKit - 1024\n"
     ]
    }
   ],
   "source": [
    "fp_types = [['morgan', 1024], ['maccs', 167], ['RDKit', 1024], ['pubchem', 881]]\n",
    "fp_type, num_bits = fp_types[2]\n",
    "#num_bits = 512\n",
    "fp_config = {\"fp_type\": fp_type,\n",
    "             \"num_bits\": num_bits}\n",
    "\n",
    "print(fp_type, '-', num_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:13:31] Explicit valence for atom # 8 Al, 6, is greater than permitted\n",
      "[17:13:32] Explicit valence for atom # 3 Al, 6, is greater than permitted\n",
      "[17:13:32] Explicit valence for atom # 4 Al, 6, is greater than permitted\n",
      "[17:13:33] Explicit valence for atom # 4 Al, 6, is greater than permitted\n",
      "[17:13:34] Explicit valence for atom # 9 Al, 6, is greater than permitted\n",
      "[17:13:34] Explicit valence for atom # 5 Al, 6, is greater than permitted\n",
      "[17:13:35] Explicit valence for atom # 16 Al, 6, is greater than permitted\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float32\n",
    "split = \"scaffold\"\n",
    "dataset = None\n",
    "if dirname != 'BBBP':\n",
    "    split = \"random\"\n",
    "    fp_array, target_array = smile_to_fp(df, fp_config=fp_config, target_name=target_name)\n",
    "    # Create Torch Dataset\n",
    "    fp_tensor = torch.tensor(fp_array, dtype=dtype)\n",
    "    target_tensor = torch.tensor(target_array, dtype=dtype).long()\n",
    "\n",
    "    dataset = TensorDataset(fp_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics ---- roc  acc f1  prs sns sps\n",
    "svm_metrics = [[], [], [], [], [], []]\n",
    "rf_metrics  = [[], [], [], [], [], []]\n",
    "knn_metrics = [[], [], [], [], [], []]\n",
    "xgb_metrics = [[], [], [], [], [], []]\n",
    "mlp_metrics = [[], [], [], [], [], []]\n",
    "metrics = [svm_metrics, rf_metrics, xgb_metrics, knn_metrics, mlp_metrics]\n",
    "\n",
    "grid_parameters = {\n",
    "    \"SVM\": {\n",
    "        \"C\": list(range(1, 100)),\n",
    "        \"kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "        \"gamma\": [\"scale\", \"auto\"],\n",
    "        \"degree\": [2, 3, 4],\n",
    "    },\n",
    "    \"RF\": {\n",
    "        \"max_depth\": [5] + list(range(10, 100, 10)),\n",
    "        \"n_estimators\": list(range(50, 400, 50)),\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "    },\n",
    "    \"XGB\": {\n",
    "        \"learning_rate\": [0.005, 0.01, 0.1, 0.2],\n",
    "        \"max_depth\": range(2, 20, 2),\n",
    "        \"n_estimators\": range(50, 400, 50),\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        \"n_neighbors\": list(range(1, 20)),\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"],\n",
    "    }\n",
    "}\n",
    "\n",
    "knn_best_params = []\n",
    "svm_best_params = []\n",
    "rf_best_params = []\n",
    "xgb_best_params = []\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(metrics_list, y_pred, y_true):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    auc_roc = roc_auc_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    sensitivity = tp/(tp + fn)\n",
    "    specificity = tn/(tn + fp)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "\n",
    "    metrics_list[0].append(accuracy)\n",
    "    metrics_list[1].append(auc_roc)\n",
    "    metrics_list[2].append(sensitivity)\n",
    "    metrics_list[3].append(specificity)\n",
    "    metrics_list[4].append(f1)\n",
    "    metrics_list[5].append(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(model, train_X, train_Y, test_X, test_Y, metrics_list):\n",
    "    model.fit(train_X,train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)\n",
    "    \n",
    "    calculate_metrics(metrics_list=metrics_list, y_true=test_Y, y_pred=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_param_search(model, grid_param, train_X, train_Y):\n",
    "    search = RandomizedSearchCV(model, grid_param, n_iter=40, scoring='roc_auc', random_state=42)\n",
    "    search.fit(train_X, train_Y)\n",
    "    return search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos_weight = (sum(train_Y == 1) / sum(train_Y == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:\n",
      "0/30\n",
      "KNN parameter search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\knsve\\AppData\\Local\\Temp\\ipykernel_14824\\1367730485.py:12: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  class_weights = compute_class_weight(class_weight='balanced', classes=np.array([0, 1]), y=np.array(train_Y))\n",
      "c:\\Users\\knsve\\Desktop\\MEI\\Tese\\torch\\snn_venv\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\knsve\\Desktop\\MEI\\Tese\\torch\\snn_venv\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "  File \"C:\\Users\\knsve\\.pyenv\\pyenv-win\\versions\\3.10.0\\lib\\subprocess.py\", line 501, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"C:\\Users\\knsve\\.pyenv\\pyenv-win\\versions\\3.10.0\\lib\\subprocess.py\", line 966, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\knsve\\.pyenv\\pyenv-win\\versions\\3.10.0\\lib\\subprocess.py\", line 1435, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM parameter search...\n",
      "Random Forest parameter search...\n",
      "XGBoost parameter search...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGBoost parameter search...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m     XGB \u001b[38;5;241m=\u001b[39m XGBClassifier(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary:logistic\u001b[39m\u001b[38;5;124m\"\u001b[39m, scale_pos_weight\u001b[38;5;241m=\u001b[39mpos_weight)\n\u001b[1;32m---> 31\u001b[0m     xgb_best_params \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_param_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXGB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_parameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mXGB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_Y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(knn_best_params, svm_best_params, rf_best_params, xgb_best_params)\n\u001b[0;32m     35\u001b[0m SVM \u001b[38;5;241m=\u001b[39m svm\u001b[38;5;241m.\u001b[39mSVC(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msvm_best_params, class_weight\u001b[38;5;241m=\u001b[39mclass_weights_dict, random_state\u001b[38;5;241m=\u001b[39mseed)\n",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m, in \u001b[0;36mrandom_param_search\u001b[1;34m(model, grid_param, train_X, train_Y)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrandom_param_search\u001b[39m(model, grid_param, train_X, train_Y):\n\u001b[0;32m      2\u001b[0m     search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(model, grid_param, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_Y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\knsve\\Desktop\\MEI\\Tese\\torch\\snn_venv\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\knsve\\Desktop\\MEI\\Tese\\torch\\snn_venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:933\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    929\u001b[0m params \u001b[38;5;241m=\u001b[39m _check_method_params(X, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m    931\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_routed_params_for_fit(params)\n\u001b[1;32m--> 933\u001b[0m cv_orig \u001b[38;5;241m=\u001b[39m check_cv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv, y, classifier\u001b[38;5;241m=\u001b[39m\u001b[43mis_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    934\u001b[0m n_splits \u001b[38;5;241m=\u001b[39m cv_orig\u001b[38;5;241m.\u001b[39mget_n_splits(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)\n\u001b[0;32m    936\u001b[0m base_estimator \u001b[38;5;241m=\u001b[39m clone(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)\n",
      "File \u001b[1;32mc:\\Users\\knsve\\Desktop\\MEI\\Tese\\torch\\snn_venv\\lib\\site-packages\\sklearn\\base.py:1237\u001b[0m, in \u001b[0;36mis_classifier\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m   1230\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1231\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing a class to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mprint\u001b[39m(inspect\u001b[38;5;241m.\u001b[39mstack()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1232\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in 1.8. Use an instance of the class instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1233\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m   1234\u001b[0m     )\n\u001b[0;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_estimator_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\knsve\\Desktop\\MEI\\Tese\\torch\\snn_venv\\lib\\site-packages\\sklearn\\utils\\_tags.py:430\u001b[0m, in \u001b[0;36mget_tags\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39mmro()):\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_tags__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n\u001b[1;32m--> 430\u001b[0m         sklearn_tags_provider[klass] \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    431\u001b[0m         class_order\u001b[38;5;241m.\u001b[39mappend(klass)\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_more_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n",
      "File \u001b[1;32mc:\\Users\\knsve\\Desktop\\MEI\\Tese\\torch\\snn_venv\\lib\\site-packages\\sklearn\\base.py:540\u001b[0m, in \u001b[0;36mClassifierMixin.__sklearn_tags__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__sklearn_tags__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m()\n\u001b[0;32m    541\u001b[0m     tags\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    542\u001b[0m     tags\u001b[38;5;241m.\u001b[39mclassifier_tags \u001b[38;5;241m=\u001b[39m ClassifierTags()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    }
   ],
   "source": [
    "iterations = 30\n",
    "print(\"Iterations:\")\n",
    "for iter in range(iterations):\n",
    "    print(str(iter) + \"/30\")\n",
    "    seed = iter+1\n",
    "    random.seed(seed)\n",
    "    train, val, test = data_splitter(df, target_name, split=split, dataset=dataset, fp_config=fp_config, seed=iter+1, dtype=dtype)\n",
    "    train_X, train_Y = train[:]\n",
    "    val_X, val_Y = val[:]\n",
    "    test_X, test_Y = test[:]\n",
    "    \n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.array([0, 1]), y=np.array(train_Y))\n",
    "    #class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "    class_weights_dict = \"balanced\"\n",
    "\n",
    "    pos_weight = (sum(train_Y == 1).numpy() / sum(train_Y == 0).numpy())\n",
    "\n",
    "\n",
    "    if iter == 0:\n",
    "        print(\"XGBoost parameter search...\")\n",
    "        XGB = XGBClassifier(objective=\"binary:logistic\", scale_pos_weight=pos_weight)\n",
    "        xgb_best_params = random_param_search(XGB, grid_parameters['XGB'], train_X, train_Y)\n",
    "        print(\"KNN parameter search...\")\n",
    "        KNN = KNeighborsClassifier()\n",
    "        knn_best_params = random_param_search(KNN, grid_parameters['KNN'], train_X, train_Y)\n",
    "        print(\"SVM parameter search...\")\n",
    "        SVM = svm.SVC(class_weight=class_weights_dict, random_state=seed)\n",
    "        svm_best_params = random_param_search(SVM, grid_parameters['SVM'], train_X, train_Y)\n",
    "        print(\"Random Forest parameter search...\")\n",
    "        RF = RandomForestClassifier(class_weight=class_weights_dict, random_state=seed)\n",
    "        rf_best_params = random_param_search(RF, grid_parameters['RF'], train_X, train_Y)\n",
    "\n",
    "        print(knn_best_params, svm_best_params, rf_best_params, xgb_best_params)\n",
    "\n",
    "    SVM = svm.SVC(**svm_best_params, class_weight=class_weights_dict, random_state=seed)\n",
    "    RF = RandomForestClassifier(**rf_best_params, class_weight=class_weights_dict, random_state=seed)\n",
    "    XGB = XGBClassifier(**xgb_best_params, objective=\"binary:logistic\", scale_pos_weight=pos_weight, random_state=seed)\n",
    "    KNN = KNeighborsClassifier(**knn_best_params)\n",
    "    MLP =  MLPClassifier(hidden_layer_sizes=(num_bits), activation='relu', solver='adam', max_iter=1000)\n",
    "\n",
    "    models = [SVM, RF, XGB, KNN, MLP]\n",
    "    for i, model in enumerate(models):\n",
    "        train_test_model(model, train_X, train_Y, test_X, test_Y, metrics[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version: 1.5.2\n",
      "xgboost version: 2.1.3\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import xgboost\n",
    "\n",
    "print(f\"scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"xgboost version: {xgboost.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.778 0.015 0.728 0.026 0.656 0.049 0.801 0.014 0.48  0.036 0.379 0.034]\n",
      " [0.86  0.013 0.655 0.027 0.356 0.057 0.954 0.009 0.441 0.052 0.587 0.05 ]\n",
      " [0.861 0.012 0.577 0.018 0.163 0.037 0.991 0.004 0.268 0.05  0.783 0.063]\n",
      " [0.863 0.013 0.611 0.025 0.244 0.049 0.978 0.005 0.355 0.06  0.666 0.079]\n",
      " [0.854 0.014 0.673 0.03  0.409 0.067 0.936 0.013 0.465 0.051 0.546 0.043]]\n",
      "results\\tox21\\ml_maccs_SR-ARE.csv\n"
     ]
    }
   ],
   "source": [
    "metric_names = ['Acc', 'AUC', 'Sn', 'Sp', 'F1', 'Precision']\n",
    "metrics = [svm_metrics, rf_metrics, xgb_metrics, knn_metrics, mlp_metrics]\n",
    "metrics_np = np.zeros((len(metrics), 12))\n",
    "\n",
    "for i, clf in enumerate(metrics):\n",
    "    metrics_np[i, 0::2] = np.round([np.mean(metric) for metric in clf], 3)\n",
    "    metrics_np[i, 1::2] = np.round([np.std(metric) for metric in clf], 3)  \n",
    "\n",
    "columns = []\n",
    "for name in metric_names:\n",
    "    columns.extend([f'Mean {name}', f'Std {name}'])\n",
    "\n",
    "print(metrics_np)\n",
    "clfs = [\"SVM\", \"RF\",\"XGB\", \"KNN\", \"MLP\"]\n",
    "df_clfs = pd.DataFrame(clfs, columns=[\"Classifier\"])\n",
    "df_metrics = pd.DataFrame(metrics_np, columns=columns)\n",
    "df = pd.concat([df_clfs, df_metrics], axis=1)\n",
    "\n",
    "if fp_type in ['maccs', 'pubchem']:\n",
    "    filename = f\"results\\\\{dirname}\\\\ml_{fp_type}_{target_name}.csv\"\n",
    "\n",
    "else:\n",
    "    filename = f\"results\\\\{dirname}\\\\ml_{fp_type}_{num_bits}_{target_name}.csv\"\n",
    "\n",
    "df.to_csv(filename, index=False)\n",
    "\n",
    "print(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
