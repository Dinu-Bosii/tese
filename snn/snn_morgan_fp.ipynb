{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from rdkit import Chem\n",
    "from snn_model import Net, device, batch_size, num_steps, train_net, test_net, get_loss_fn, num_hidden\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from snntorch import spikegen, surrogate\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import load_dataset_df, fp_generator\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, f1_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['tox21.csv','sider.csv', 'BBBP.csv']\n",
    "dt_file = files[2]\n",
    "\n",
    "df, targets = load_dataset_df(filename=dt_file)\n",
    "print(targets)\n",
    "\n",
    "target_name = targets[0]\n",
    "df = df[[target_name, 'smiles']].dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Molecule to Fingerprint Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import Draw, AllChem\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "row = df.iloc[random.randint(0, len(df))]\n",
    "\n",
    "mol = Chem.MolFromSmiles(row['smiles'])\n",
    "\n",
    "if mol is not None:\n",
    "    img = Draw.MolToImage(mol)\n",
    "print(row['smiles'])\n",
    "\n",
    "fpgen = fp_generator('morgan')\n",
    "ao = AllChem.AdditionalOutput()\n",
    "ao.CollectBitInfoMap()\n",
    "\n",
    "fp = fpgen(mol,additionalOutput=ao)\n",
    "bi = ao.GetBitInfoMap()\n",
    "\n",
    "fp = np.array(fp)\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(20, 20))\n",
    "fig2, axs2 = plt.subplots(1, 5, figsize=(20, 20))\n",
    "\n",
    "for i, id in enumerate(list(bi.keys())[:5]):\n",
    "    print(id, bi[id])\n",
    "    mfp2_svg = Draw.DrawMorganBit(mol, bitId=id, bitInfo=bi)\n",
    "\n",
    "    atoms = [info[0] for info in bi[id]]\n",
    "    colors = {idx: (1, 1, 0) for idx in atoms}\n",
    "\n",
    "    img2 = Draw.MolToImage(mol, highlightAtoms=atoms, highlightAtomColors=colors)\n",
    "    \n",
    "    axs[i].imshow(mfp2_svg)\n",
    "    axs2[i].imshow(img2)\n",
    "\n",
    "\n",
    "    #display(img)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMILE to Fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_types = [['morgan', 1024], ['maccs', 167], ['RDKit', 1024]]\n",
    "fp_type, num_bits = fp_types[0]\n",
    "print(fp_type, '-', num_bits)\n",
    "num_rows = len(df)\n",
    "fp_array = np.zeros((num_rows, num_bits))\n",
    "target_array = np.zeros((num_rows, 1))\n",
    "i = 0\n",
    "\n",
    "img = None\n",
    "# Smile to Fingerprint of size {num_bits}\n",
    "fp_gen = fp_generator(fp_type)\n",
    "for idx, row in df.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['smiles'])\n",
    "    #TODO: sanitize molecules to remove the warnings (?)\n",
    "    \n",
    "    if mol is not None:\n",
    "        fingerprint = fp_gen(mol)\n",
    "\n",
    "        fp_array[i] = np.array(fingerprint)\n",
    "        target_array[i] = row[target_name]\n",
    "        i += 1\n",
    "target_array = target_array.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Torch Dataset\n",
    "dtype = torch.float32\n",
    "fp_tensor = torch.tensor(fp_array, dtype=dtype)\n",
    "target_tensor = torch.tensor(target_array, dtype=dtype).long()\n",
    "\n",
    "dataset = TensorDataset(fp_tensor, target_tensor)\n",
    "\"\"\" \n",
    "generator = torch.Generator().manual_seed(iter + 1)\n",
    "train, test = random_split(dataset, [0.7, 0.3], generator=generator)\n",
    "\n",
    "_, train_label = train[:]\n",
    "_, test_label = test[:]\n",
    "\n",
    "\n",
    "print(\"positive labels in the test set:\", int(test_label.sum()))\n",
    "\n",
    "# Load the Data\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "print(len(train), len(test)) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function + Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------\n",
    "#binary cross entropy\n",
    "#racio do pos:neg\n",
    "#BCEWithLogitsLoss: pos_weight parameter\n",
    "# -----------------\n",
    "#output of snn (for rate encoding) -> number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "loss_types = ['cross_entropy', 'rate_loss', 'temporal_loss']\n",
    "loss_type = loss_types[1]\n",
    "print(loss_type)\n",
    "\n",
    "#possibly move to train fn to always calculate weights on train split\n",
    "use_weights = False\n",
    "\n",
    "\n",
    "\"\"\" if use_weights:\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.array([0, 1]), y=np.array(train_label))\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "    weighted = 'class_weights'\n",
    "else: \n",
    "    class_weights=None\n",
    "    weighted = ''\n",
    "    \n",
    "\n",
    "loss_fn = get_loss_fn(loss_type=loss_type, class_weights=class_weights) \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "iterations = 30\n",
    "#counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [[], [], [], [], [], []]\n",
    "for iter in range(iterations):\n",
    "    print(f\"Iteration:{iter + 1}/{iterations}\")\n",
    "    random.seed(iter)\n",
    "    #spike_grad=surrogate.fast_sigmoid()\n",
    "    spike_grad=None\n",
    "    net = Net(num_inputs=num_bits, spike_grad=spike_grad).to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999), weight_decay=0)\n",
    "\n",
    "    generator = torch.Generator().manual_seed(iter + 1)\n",
    "    train, test = random_split(dataset, [0.7, 0.3], generator=generator)\n",
    "\n",
    "    _, train_label = train[:]\n",
    "    _, test_label = test[:]\n",
    "\n",
    "\n",
    "    print(\"positive labels in the test set:\", int(test_label.sum()))\n",
    "\n",
    "    # Load the Data\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    #Loss Function\n",
    "    if use_weights:\n",
    "        class_weights = compute_class_weight(class_weight='balanced', classes=np.array([0, 1]), y=np.array(train_label))\n",
    "        class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "        weighted = 'class_weights'\n",
    "    else: \n",
    "        class_weights=None\n",
    "        weighted = ''\n",
    "\n",
    "    loss_fn = get_loss_fn(loss_type=loss_type, class_weights=class_weights)\n",
    "\n",
    "    net, loss_hist = train_net(net, optimizer, num_steps, device, num_epochs, train_loader, loss_type, loss_fn, dtype)\n",
    "\n",
    "    #fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "    #plt.plot(loss_hist)\n",
    "    #plt.title(\"Loss Curve\")\n",
    "    #plt.xlabel(\"Iteration\")\n",
    "    #plt.ylabel(\"Loss\")\n",
    "    #plt.show()\n",
    "\n",
    "    all_preds, all_targets = test_net(net, device, test_loader)\n",
    "\n",
    "    accuracy = accuracy_score(all_targets, all_preds)\n",
    "    auc_roc = roc_auc_score(all_targets, all_preds)\n",
    "    tn, fp, fn, tp = confusion_matrix(all_targets, all_preds).ravel()\n",
    "    sensitivity = tp/(tp + fn)\n",
    "    specificity = tn/(tn + fp)\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "    precision = precision_score(all_targets, all_preds)\n",
    "\n",
    "    results[0].append(accuracy)\n",
    "    results[1].append(auc_roc)\n",
    "    results[2].append(sensitivity)\n",
    "    results[3].append(specificity)\n",
    "    results[4].append(f1)\n",
    "    results[5].append(precision)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smoothed Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "print(loss_hist[len(loss_hist) - 5:len(loss_hist)])\n",
    "\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "#plt.plot(np.convolve(loss_hist, np.ones(30)/30, mode='valid'))\n",
    "#plt.plot(savgol_filter(loss_hist, window_length=100, polyorder=3))\n",
    "#plt.plot(lowess(loss_hist, np.arange(len(loss_hist)), frac=0.1)[:, 1])\n",
    "plt.plot(gaussian_filter1d(loss_hist, sigma=6))\n",
    "plt.axhline(y=1, color='r', linestyle='--', label='y = 1')\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_np = np.zeros(12)\n",
    "\n",
    "for i, metric in enumerate(results):\n",
    "    metrics_np[i*2] = np.round(np.mean(metric), 3)\n",
    "    metrics_np[i*2+1] = np.round(np.std(metric), 3)\n",
    "\n",
    "# Print Results\n",
    "print(f\"Accuracy:  {metrics_np[0]:.2f} ± {metrics_np[1]:.2f}\")\n",
    "print(f\"AUC ROC: {metrics_np[2]:.2f} ± {metrics_np[3]:.2f}\")\n",
    "print(f\"Sensitivity: {metrics_np[4]:.2f} ± {metrics_np[5]:.2f}\")\n",
    "print(f\"Specificity: {metrics_np[6]:.2f} ± {metrics_np[7]:.2f}\")\n",
    "\n",
    "metric_names = ['Acc', 'AUC', 'Sn', 'Sp', 'F1', 'Precision']\n",
    "metrics_np = metrics_np.reshape(1, -1)\n",
    "columns = []\n",
    "for name in metric_names:\n",
    "    columns.extend([f'Mean {name}', f'Std {name}'])\n",
    "\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics_np, columns=columns)\n",
    "dirname = dt_file.strip('.csv')\n",
    "\n",
    "filename = f\"results\\\\{dirname}\\\\{target_name}_{fp_type}_{num_bits}_{num_hidden}_{loss_type}_{weighted}.csv\"\n",
    "df_metrics.to_csv(filename, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchviz import make_dot\n",
    "#train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "#batch = next(iter(train_loader))\n",
    "#data, target = batch  # Assuming batch is structured as (data, target)\n",
    "#net = Net(num_inputs=num_bits, spike_grad=None).to(device)\n",
    "#yhat = net(data)\n",
    "#make_dot(yhat, params=dict(list(net.named_parameters()))).render(\"snn_torchviz\", format=\"png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
