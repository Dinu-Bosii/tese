{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "No normalization for NumAmideBonds. Feature removed!\n",
      "No normalization for NumAtomStereoCenters. Feature removed!\n",
      "No normalization for NumBridgeheadAtoms. Feature removed!\n",
      "No normalization for NumHeterocycles. Feature removed!\n",
      "No normalization for NumSpiroAtoms. Feature removed!\n",
      "No normalization for NumUnspecifiedAtomStereoCenters. Feature removed!\n",
      "No normalization for Phi. Feature removed!\n",
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (c:\\Users\\knsve\\Desktop\\MEI\\Tese\\torch\\snn_venv\\lib\\site-packages\\deepchem\\models\\torch_models\\__init__.py)\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (c:\\Users\\knsve\\Desktop\\MEI\\Tese\\torch\\snn_venv\\lib\\site-packages\\deepchem\\models\\torch_models\\__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "Skipped loading some PyTorch models, missing a dependency. No module named 'tensorflow'\n",
      "c:\\Users\\knsve\\Desktop\\MEI\\Tese\\torch\\snn_venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from utils import load_dataset_df,  data_splitter, get_spiking_net, make_filename, smiles_to_feat\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, f1_score, precision_score\n",
    "from csnn_model import get_prediction_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['tox21.csv','sider.csv', 'BBBP.csv']\n",
    "dt_file = files[0]\n",
    "dirname = dt_file.removesuffix('.csv')\n",
    "\n",
    "df, targets = load_dataset_df(filename=dt_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dirname == 'tox21':\n",
    "    # SR-ARE\n",
    "    target_name = targets[7]\n",
    "    # SR-MMP\n",
    "elif dirname == 'sider':\n",
    "    #Hepatobiliary disorders 1427 samples, 0.52 class ratio\n",
    "    target_name = targets[0]\n",
    "else:\n",
    "    target_name = targets[0]\n",
    "    \n",
    "df = df[[target_name, 'smiles']].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Molecular Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = [\"fp\", \"descriptor\"]\n",
    "\n",
    "repr_type = representations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDKit - 512\n",
      "morgan - 512\n",
      "fp\n"
     ]
    }
   ],
   "source": [
    "if repr_type == \"fp\":\n",
    "    fp_types = [['morgan', 1024], ['maccs', 167], ['RDKit', 1024], ['count_morgan', 1024], ['pubchem', 881]]\n",
    "    mix = True\n",
    "    fp_type, num_bits = fp_types[2]\n",
    "    if mix and fp_type == 'RDKit':\n",
    "        num_bits = 512\n",
    "    data_config = {\"fp_type\": fp_type,\n",
    "                \"num_bits\": num_bits,\n",
    "                \"radius\": 2,\n",
    "                \"fp_type_2\": fp_types[0][0],\n",
    "                \"num_bits_2\": 1024 - num_bits,\n",
    "                \"mix\": mix,\n",
    "                \"dim_2\": False}\n",
    "    dim_2 = data_config['dim_2']\n",
    "    print(fp_type, '-', num_bits)\n",
    "    if mix: print(data_config['fp_type_2'], '-', data_config['num_bits_2'])\n",
    "    if dim_2: print(\"2D FP\")\n",
    "\n",
    "elif repr_type == \"descriptor\":\n",
    "    mix = False\n",
    "    desc_type = [\"RDKit\", \"Mordred\"]\n",
    "    data_config = {\"desc_type\": desc_type[0],\n",
    "                   \"size\": 0,\n",
    "                }\n",
    "\n",
    "data_config[\"repr_type\"] = repr_type\n",
    "print(repr_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:18:16] Explicit valence for atom # 8 Al, 6, is greater than permitted\n",
      "[09:18:17] Explicit valence for atom # 3 Al, 6, is greater than permitted\n",
      "[09:18:17] Explicit valence for atom # 4 Al, 6, is greater than permitted\n",
      "[09:18:18] Explicit valence for atom # 4 Al, 6, is greater than permitted\n",
      "[09:18:19] Explicit valence for atom # 9 Al, 6, is greater than permitted\n",
      "[09:18:19] Explicit valence for atom # 5 Al, 6, is greater than permitted\n",
      "[09:18:20] Explicit valence for atom # 16 Al, 6, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5825, 1024])\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "split = \"scaffold\" if dirname == \"BBBP\" else \"random\"\n",
    "dataset = None\n",
    "\n",
    "\n",
    "feat_tensor, target_tensor, feat_df = smiles_to_feat(df,repr_type=repr_type, data_config=data_config, target_name=target_name, dtype=dtype)\n",
    "print(feat_tensor.shape)\n",
    "dataset = TensorDataset(feat_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_loss\n"
     ]
    }
   ],
   "source": [
    "loss_types = ['ce_mem', 'rate_loss', 'count_loss', 'temporal_loss', 'bce_loss']\n",
    "loss_type = loss_types[2]\n",
    "print(loss_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_types = [\"SNN\", \"DSNN\", \"CSNN\", \"RSNN\"]\n",
    "net_type = net_types[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSNN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "slope = 10\n",
    "#spike_grad = surrogate.fast_sigmoid(slope=slope)\n",
    "spike_grad = None\n",
    "beta = 0.95\n",
    "bias = True\n",
    "net_config = {\n",
    "            \"num_hidden\": 1024,\n",
    "            \"num_hidden_l2\": 256,\n",
    "            \"num_steps\": 10,\n",
    "            \"spike_grad\": spike_grad,\n",
    "            \"slope\": None if not spike_grad else slope, #spike_grad.__closure__[0].cell_contents,\n",
    "            \"beta\": beta,\n",
    "            \"encoding\": 'rate' if loss_type != 'temporal_loss' else 'ttfs',\n",
    "            \"bias\": bias,\n",
    "            \"out_num\": 2,\n",
    "            \"num_hidden_layers\": 2,\n",
    "            \"num_hidden_l3\": 256,\n",
    "            }\n",
    "if net_type == \"CSNN\":\n",
    "    net_config['num_conv'] = 1\n",
    "    net_config[\"pool_size\"] = 2\n",
    "    net_config[\"conv_kernel\"] = 3\n",
    "    net_config[\"conv_stride\"] = [1 for _ in range(net_config['num_conv'])]\n",
    "    net_config[\"conv_groups\"] = 1\n",
    "\n",
    "if repr_type == \"fp\":\n",
    "    net_config[\"input_size\"] = 1024 if data_config['mix'] else num_bits\n",
    "    net_config[\"2d\"] = data_config['dim_2']\n",
    "\n",
    "elif repr_type == \"descriptor\":\n",
    "    net_config[\"input_size\"] = feat_tensor.shape[1]\n",
    "    net_config[\"2d\"] = False\n",
    "    #net_config[\"num_steps\"] = 10\n",
    "\n",
    "print(net_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "<function prediction_spk_rate_scores at 0x0000027861A8E950>\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "pop_coding = net_config['out_num'] > 2\n",
    "lr=1e-4\n",
    "iterations = 30\n",
    "weight_decay = 0 # 1e-5\n",
    "#weight_decay = 1e-4\n",
    "optim_type = 'Adam'\n",
    "#optim_type = 'SGD'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "batch_size = 16 #16, 8\n",
    "scores = True\n",
    "train_config = {\"num_epochs\": 100,\n",
    "                \"batch_size\": batch_size,\n",
    "                \"device\": device,\n",
    "                \"loss_type\": loss_type,\n",
    "                \"loss_fn\": None,\n",
    "                'dtype': dtype,\n",
    "                'num_steps': net_config['num_steps'],\n",
    "                'val_net': None,\n",
    "                'prediction_fn': get_prediction_fn(encoding=net_config['encoding'], pop_coding=pop_coding, scores=scores),\n",
    "                }\n",
    "drop_last = net_type == \"CSNN\"\n",
    "pin_memory = device == \"cuda\"\n",
    "save_csv = True\n",
    "save_models = True\n",
    "print(train_config[\"prediction_fn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_scores = True\n",
    "\n",
    "def calc_metrics(metrics_list, all_targets, all_preds):\n",
    "    if calculate_scores:\n",
    "        auc_roc = roc_auc_score(all_targets, all_preds)\n",
    "        all_preds = np.array(all_preds) > 0.0\n",
    "    else:\n",
    "        all_preds = np.array(all_preds) > 0.0\n",
    "        auc_roc = roc_auc_score(all_targets, all_preds)\n",
    "    \n",
    "    accuracy = accuracy_score(all_targets, all_preds)\n",
    "    tn, fp, fn, tp = confusion_matrix(all_targets, all_preds).ravel()\n",
    "    sensitivity = tp/(tp + fn)\n",
    "    specificity = tn/(tn + fp)\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "    precision = precision_score(all_targets, all_preds)\n",
    "    print(\"acc:\", accuracy, \"auc:\", auc_roc)\n",
    "    metrics_list[0].append(accuracy)\n",
    "    metrics_list[1].append(auc_roc)\n",
    "    metrics_list[2].append(sensitivity)\n",
    "    metrics_list[3].append(specificity)\n",
    "    metrics_list[4].append(f1)\n",
    "    metrics_list[5].append(precision)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "results\\tox21\\models\\\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "net_list = []\n",
    "    \n",
    "net, train_net, val_net, test_net = get_spiking_net(net_type, net_config)\n",
    "filename = make_filename(dirname, target_name, net_type, data_config, lr, weight_decay, optim_type, net_config, train_config, net, model = True)\n",
    "\n",
    "model_name = filename.removesuffix('.csv')\n",
    "\n",
    "models_path = os.path.join(\"results\", dirname, \"models\", \"\")\n",
    "all_model_names = os.listdir(models_path)\n",
    "print(models_path)\n",
    "#print(all_model_names)\n",
    "for iter in range(iterations):\n",
    "    seed = int(iter + 1)\n",
    "    string_id = f\"seed-{seed}.pth\"\n",
    "    search_name = model_name + str(string_id) \n",
    "    search_name_no_folder = search_name.removeprefix(models_path)\n",
    "    if search_name_no_folder in all_model_names:\n",
    "        state_dict = torch.load(search_name, weights_only=True)\n",
    "        net_list.append(copy.deepcopy(state_dict))\n",
    "    else: print(search_name_no_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(net_list) < 30:\n",
    "    net_list = []\n",
    "    for iter in range(iterations):\n",
    "        seed = int(iter + 1)\n",
    "        string_id = f\"-scores-seed-{seed}.pth\"\n",
    "        search_name = model_name + str(string_id) \n",
    "        search_name_no_folder = search_name.removeprefix(models_path)\n",
    "        if search_name_no_folder in all_model_names:\n",
    "            state_dict = torch.load(search_name, weights_only=True)\n",
    "            net_list.append(copy.deepcopy(state_dict))\n",
    "\n",
    "if len(net_list) < 30:\n",
    "    net_list = []\n",
    "    for iter in range(iterations):\n",
    "        seed = int(iter + 1)\n",
    "        string_id = f\"seed-{seed}_auc.pth\"\n",
    "        search_name = model_name + str(string_id) \n",
    "        search_name_no_folder = search_name.removeprefix(models_path)\n",
    "        if search_name_no_folder in all_model_names:\n",
    "            state_dict = torch.load(search_name, weights_only=True)\n",
    "            net_list.append(copy.deepcopy(state_dict))\n",
    "        #else: print(search_name_no_folder)\n",
    "\n",
    "if len(net_list) < 30: print(\"No models found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_norm(train_subset, val_subset, test_subset):\n",
    "    train_tensor, _ = train_subset[:]\n",
    "    val_tensor, _ = val_subset[:]\n",
    "    test_tensor, _ = test_subset[:]\n",
    "\n",
    "    min_val = train_tensor.min(dim=0).values\n",
    "    max_val = train_tensor.max(dim=0).values\n",
    "    range_val = (max_val - min_val).clamp(min=1e-6)\n",
    "\n",
    "    train_norm = ((train_tensor - min_val) / range_val).clamp(0.0, 1.0)\n",
    "    val_norm   = ((val_tensor   - min_val) / range_val).clamp(0.0, 1.0)\n",
    "    test_norm  = ((test_tensor  - min_val) / range_val).clamp(0.0, 1.0)\n",
    "\n",
    "    return train_norm, val_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:1 -> acc: 0.8178694158075601 auc: 0.8768036886848768\n",
      "Seed:2 -> acc: 0.8127147766323024 auc: 0.8683847822121328\n",
      "Seed:3 -> acc: 0.8694158075601375 auc: 0.8653213398035271\n",
      "Seed:4 -> acc: 0.8470790378006873 auc: 0.909548780487805\n",
      "Seed:5 -> acc: 0.9518900343642611 auc: 0.958269708503316\n",
      "Seed:6 -> acc: 0.8264604810996563 auc: 0.9004956396260744\n",
      "Seed:7 -> acc: 0.8333333333333334 auc: 0.8629618342085521\n",
      "Seed:8 -> acc: 0.8487972508591065 auc: 0.874497103315095\n",
      "Seed:9 -> acc: 0.8213058419243986 auc: 0.872042261697434\n",
      "Seed:10 -> acc: 0.8573883161512027 auc: 0.8783037475345169\n",
      "Seed:11 -> acc: 0.8539518900343642 auc: 0.8865821678321677\n",
      "Seed:12 -> acc: 0.8436426116838488 auc: 0.8937898537134285\n",
      "Seed:13 -> acc: 0.915807560137457 auc: 0.9467642984365723\n",
      "Seed:14 -> acc: 0.8608247422680413 auc: 0.8919376693766938\n",
      "Seed:15 -> acc: 0.8316151202749141 auc: 0.8660408093278463\n",
      "Seed:16 -> acc: 0.8264604810996563 auc: 0.9049848178137652\n",
      "Seed:17 -> acc: 0.8144329896907216 auc: 0.877274456704192\n",
      "Seed:18 -> acc: 0.7525773195876289 auc: 0.8558506224066389\n",
      "Seed:19 -> acc: 0.8213058419243986 auc: 0.8975143196801036\n",
      "Seed:20 -> acc: 0.8556701030927835 auc: 0.8472488664108825\n",
      "Seed:21 -> acc: 0.8505154639175257 auc: 0.9015149608677051\n",
      "Seed:22 -> acc: 0.8144329896907216 auc: 0.8678297199638664\n",
      "Seed:23 -> acc: 0.8487972508591065 auc: 0.9164379120285313\n",
      "Seed:24 -> acc: 0.8144329896907216 auc: 0.8968149402932012\n",
      "Seed:25 -> acc: 0.8883161512027491 auc: 0.9062492602674873\n",
      "Seed:26 -> acc: 0.654639175257732 auc: 0.8578594962270167\n",
      "Seed:27 -> acc: 0.8092783505154639 auc: 0.9066829301045186\n",
      "Seed:28 -> acc: 0.8333333333333334 auc: 0.8353998343815044\n",
      "Seed:29 -> acc: 0.8883161512027491 auc: 0.9319957028714666\n",
      "Seed:30 -> acc: 0.8075601374570447 auc: 0.8444746043430253\n"
     ]
    }
   ],
   "source": [
    "results = [[], [], [], [], [], []]\n",
    "for iter in range(iterations):\n",
    "    #print(f\"Iteration:{iter + 1}/{iterations}\")\n",
    "    seed = iter + 1\n",
    "    print(f\"Seed:{seed} -> \",end='', flush=True)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # DATA SPLIT\n",
    "    train, val, test = data_splitter(df, target_name, split=split, dataset=dataset, data_config=data_config, seed=seed, dtype=dtype)\n",
    "    _, train_label = train[:]\n",
    "    _, val_label = val[:]\n",
    "    _, test_label = test[:]\n",
    "\n",
    "    if repr_type == \"descriptor\":\n",
    "        train_data, val_data, test_data = minmax_norm(train, val, test)\n",
    "        train = TensorDataset(train_data, train_label)\n",
    "        val = TensorDataset(val_data,val_label)\n",
    "        test = TensorDataset(test_data, test_label)\n",
    "        \n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, pin_memory=pin_memory, drop_last=drop_last)\n",
    "    val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, pin_memory=pin_memory)\n",
    "    test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, pin_memory=pin_memory)\n",
    "\n",
    "    # TESTING\n",
    "    model = net\n",
    "    flag = False\n",
    "    try:\n",
    "        loaded_result = model.load_state_dict(net_list[iter])\n",
    "    except RuntimeError as e:\n",
    "        print(f\"{e}\")\n",
    "        model.load_state_dict(net_list[iter], strict=False)\n",
    "        flag = True\n",
    "    model.to(device)\n",
    "\n",
    "    all_preds, all_targets = test_net(model, device, test_loader, train_config)\n",
    "    calc_metrics(results, all_preds=all_preds, all_targets=all_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [3., 1.],\n",
      "        [1., 0.],\n",
      "        [3., 3.],\n",
      "        [1., 1.],\n",
      "        [2., 3.],\n",
      "        [0., 1.],\n",
      "        [2., 2.],\n",
      "        [1., 2.],\n",
      "        [0., 3.],\n",
      "        [3., 2.],\n",
      "        [0., 0.],\n",
      "        [3., 3.],\n",
      "        [1., 3.]], device='cuda:0')\n",
      "tensor([[2., 0.],\n",
      "        [3., 1.],\n",
      "        [2., 3.],\n",
      "        [3., 2.],\n",
      "        [3., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [2., 3.],\n",
      "        [1., 2.],\n",
      "        [3., 1.],\n",
      "        [0., 3.],\n",
      "        [3., 1.],\n",
      "        [1., 1.],\n",
      "        [2., 1.],\n",
      "        [2., 2.],\n",
      "        [0., 1.]], device='cuda:0')\n",
      "tensor([[3., 3.],\n",
      "        [4., 0.],\n",
      "        [3., 1.],\n",
      "        [2., 1.],\n",
      "        [4., 1.],\n",
      "        [3., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [4., 1.],\n",
      "        [3., 1.],\n",
      "        [3., 2.],\n",
      "        [4., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 3.],\n",
      "        [1., 3.]], device='cuda:0')\n",
      "tensor([[1., 1.],\n",
      "        [2., 3.],\n",
      "        [0., 1.],\n",
      "        [3., 2.],\n",
      "        [0., 1.],\n",
      "        [2., 1.],\n",
      "        [2., 2.],\n",
      "        [2., 1.],\n",
      "        [2., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 2.],\n",
      "        [2., 3.],\n",
      "        [2., 1.],\n",
      "        [2., 1.],\n",
      "        [2., 2.]], device='cuda:0')\n",
      "tensor([[2., 0.],\n",
      "        [2., 3.],\n",
      "        [4., 1.],\n",
      "        [3., 3.],\n",
      "        [2., 2.],\n",
      "        [0., 0.],\n",
      "        [3., 1.],\n",
      "        [3., 1.],\n",
      "        [1., 1.],\n",
      "        [0., 1.],\n",
      "        [2., 1.],\n",
      "        [3., 3.],\n",
      "        [4., 2.],\n",
      "        [3., 2.],\n",
      "        [1., 1.],\n",
      "        [3., 0.]], device='cuda:0')\n",
      "tensor([[5., 1.],\n",
      "        [2., 1.],\n",
      "        [1., 3.],\n",
      "        [4., 2.],\n",
      "        [0., 1.],\n",
      "        [3., 1.],\n",
      "        [4., 2.],\n",
      "        [1., 0.],\n",
      "        [2., 1.],\n",
      "        [2., 2.],\n",
      "        [4., 1.],\n",
      "        [3., 2.],\n",
      "        [1., 2.],\n",
      "        [3., 1.],\n",
      "        [1., 0.],\n",
      "        [2., 2.]], device='cuda:0')\n",
      "tensor([[0., 0.],\n",
      "        [5., 1.],\n",
      "        [2., 2.],\n",
      "        [1., 0.],\n",
      "        [2., 2.],\n",
      "        [4., 2.],\n",
      "        [4., 2.],\n",
      "        [3., 1.],\n",
      "        [2., 0.],\n",
      "        [3., 0.],\n",
      "        [2., 2.],\n",
      "        [0., 0.],\n",
      "        [4., 3.],\n",
      "        [2., 3.],\n",
      "        [4., 0.],\n",
      "        [0., 1.]], device='cuda:0')\n",
      "tensor([[1., 3.],\n",
      "        [0., 0.],\n",
      "        [2., 1.],\n",
      "        [4., 2.],\n",
      "        [0., 1.],\n",
      "        [3., 1.],\n",
      "        [3., 1.],\n",
      "        [1., 3.],\n",
      "        [0., 1.],\n",
      "        [1., 3.],\n",
      "        [1., 1.],\n",
      "        [4., 2.],\n",
      "        [0., 1.],\n",
      "        [3., 1.],\n",
      "        [3., 3.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "tensor([[3., 1.],\n",
      "        [2., 2.],\n",
      "        [2., 2.],\n",
      "        [0., 1.],\n",
      "        [4., 1.],\n",
      "        [3., 2.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [3., 2.],\n",
      "        [4., 1.],\n",
      "        [1., 0.],\n",
      "        [3., 2.],\n",
      "        [2., 2.],\n",
      "        [1., 0.],\n",
      "        [4., 3.],\n",
      "        [1., 1.]], device='cuda:0')\n",
      "tensor([[0., 0.],\n",
      "        [5., 1.],\n",
      "        [2., 0.],\n",
      "        [4., 1.],\n",
      "        [3., 2.],\n",
      "        [2., 2.],\n",
      "        [3., 0.],\n",
      "        [4., 0.],\n",
      "        [1., 3.],\n",
      "        [1., 1.],\n",
      "        [4., 1.],\n",
      "        [1., 2.],\n",
      "        [4., 1.],\n",
      "        [2., 1.],\n",
      "        [1., 1.],\n",
      "        [0., 1.]], device='cuda:0')\n",
      "tensor([[1., 0.],\n",
      "        [3., 1.],\n",
      "        [2., 2.],\n",
      "        [3., 2.],\n",
      "        [2., 1.],\n",
      "        [0., 2.],\n",
      "        [2., 1.],\n",
      "        [2., 3.],\n",
      "        [3., 3.],\n",
      "        [0., 3.],\n",
      "        [3., 0.],\n",
      "        [2., 2.],\n",
      "        [1., 0.],\n",
      "        [2., 2.],\n",
      "        [0., 2.],\n",
      "        [1., 2.]], device='cuda:0')\n",
      "tensor([[3., 2.],\n",
      "        [3., 1.],\n",
      "        [1., 3.],\n",
      "        [4., 1.],\n",
      "        [3., 1.],\n",
      "        [1., 2.],\n",
      "        [4., 1.],\n",
      "        [0., 1.],\n",
      "        [3., 1.],\n",
      "        [1., 3.],\n",
      "        [5., 1.],\n",
      "        [3., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 3.],\n",
      "        [1., 3.],\n",
      "        [0., 2.]], device='cuda:0')\n",
      "tensor([[3., 2.],\n",
      "        [0., 0.],\n",
      "        [2., 1.],\n",
      "        [4., 2.],\n",
      "        [3., 1.],\n",
      "        [3., 1.],\n",
      "        [5., 1.],\n",
      "        [2., 2.],\n",
      "        [5., 0.],\n",
      "        [4., 2.],\n",
      "        [3., 3.],\n",
      "        [2., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 1.],\n",
      "        [0., 2.],\n",
      "        [4., 1.]], device='cuda:0')\n",
      "tensor([[3., 1.],\n",
      "        [3., 2.],\n",
      "        [2., 3.],\n",
      "        [2., 2.],\n",
      "        [2., 4.],\n",
      "        [1., 1.],\n",
      "        [4., 1.],\n",
      "        [2., 0.],\n",
      "        [4., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [3., 1.],\n",
      "        [1., 4.],\n",
      "        [3., 0.],\n",
      "        [2., 1.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "tensor([[0., 3.],\n",
      "        [0., 0.],\n",
      "        [2., 3.],\n",
      "        [0., 0.],\n",
      "        [2., 1.],\n",
      "        [2., 2.],\n",
      "        [0., 0.],\n",
      "        [1., 2.],\n",
      "        [0., 0.],\n",
      "        [4., 3.],\n",
      "        [3., 1.],\n",
      "        [3., 2.],\n",
      "        [0., 2.],\n",
      "        [5., 1.],\n",
      "        [4., 2.],\n",
      "        [3., 2.]], device='cuda:0')\n",
      "tensor([[2., 2.],\n",
      "        [2., 2.],\n",
      "        [1., 2.],\n",
      "        [2., 2.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [4., 3.],\n",
      "        [2., 3.],\n",
      "        [5., 0.],\n",
      "        [4., 1.],\n",
      "        [0., 0.],\n",
      "        [5., 1.],\n",
      "        [2., 2.],\n",
      "        [3., 2.],\n",
      "        [1., 4.],\n",
      "        [4., 1.]], device='cuda:0')\n",
      "tensor([[3., 2.],\n",
      "        [1., 2.],\n",
      "        [3., 2.],\n",
      "        [2., 2.],\n",
      "        [1., 0.],\n",
      "        [2., 3.],\n",
      "        [5., 1.],\n",
      "        [1., 2.],\n",
      "        [3., 1.],\n",
      "        [2., 3.],\n",
      "        [3., 2.],\n",
      "        [0., 0.],\n",
      "        [2., 1.],\n",
      "        [1., 0.],\n",
      "        [3., 0.],\n",
      "        [2., 2.]], device='cuda:0')\n",
      "tensor([[2., 2.],\n",
      "        [3., 2.],\n",
      "        [5., 2.],\n",
      "        [0., 2.],\n",
      "        [2., 0.],\n",
      "        [1., 2.],\n",
      "        [0., 1.],\n",
      "        [2., 0.],\n",
      "        [3., 3.],\n",
      "        [0., 0.],\n",
      "        [4., 1.],\n",
      "        [0., 0.],\n",
      "        [4., 2.],\n",
      "        [3., 2.],\n",
      "        [3., 2.],\n",
      "        [1., 0.]], device='cuda:0')\n",
      "tensor([[3., 2.],\n",
      "        [3., 2.],\n",
      "        [0., 3.],\n",
      "        [3., 2.],\n",
      "        [4., 2.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [2., 2.],\n",
      "        [0., 1.],\n",
      "        [4., 1.],\n",
      "        [0., 0.],\n",
      "        [1., 1.],\n",
      "        [3., 0.],\n",
      "        [3., 4.],\n",
      "        [3., 2.],\n",
      "        [1., 0.]], device='cuda:0')\n",
      "tensor([[4., 1.],\n",
      "        [3., 1.],\n",
      "        [2., 3.],\n",
      "        [0., 2.],\n",
      "        [2., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [2., 1.],\n",
      "        [1., 1.],\n",
      "        [3., 1.],\n",
      "        [3., 2.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [4., 1.],\n",
      "        [0., 0.],\n",
      "        [3., 2.]], device='cuda:0')\n",
      "tensor([[4., 2.],\n",
      "        [4., 1.],\n",
      "        [3., 1.],\n",
      "        [5., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 0.],\n",
      "        [3., 2.],\n",
      "        [2., 2.],\n",
      "        [1., 3.],\n",
      "        [3., 1.],\n",
      "        [4., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 2.],\n",
      "        [4., 1.],\n",
      "        [4., 1.],\n",
      "        [2., 2.]], device='cuda:0')\n",
      "tensor([[3., 2.],\n",
      "        [3., 1.],\n",
      "        [3., 1.],\n",
      "        [5., 0.],\n",
      "        [4., 2.],\n",
      "        [3., 2.],\n",
      "        [2., 2.],\n",
      "        [1., 3.],\n",
      "        [3., 2.],\n",
      "        [5., 1.],\n",
      "        [2., 0.],\n",
      "        [0., 2.],\n",
      "        [0., 1.],\n",
      "        [1., 2.],\n",
      "        [3., 1.],\n",
      "        [3., 2.]], device='cuda:0')\n",
      "tensor([[3., 1.],\n",
      "        [3., 3.],\n",
      "        [0., 2.],\n",
      "        [1., 1.],\n",
      "        [1., 4.],\n",
      "        [1., 2.],\n",
      "        [1., 0.],\n",
      "        [2., 2.],\n",
      "        [2., 2.],\n",
      "        [2., 2.],\n",
      "        [4., 3.],\n",
      "        [4., 1.],\n",
      "        [1., 4.],\n",
      "        [2., 2.],\n",
      "        [5., 2.],\n",
      "        [3., 4.]], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 2.],\n",
      "        [3., 2.],\n",
      "        [4., 1.],\n",
      "        [3., 0.],\n",
      "        [3., 1.],\n",
      "        [3., 2.],\n",
      "        [0., 0.],\n",
      "        [2., 3.],\n",
      "        [2., 1.],\n",
      "        [0., 0.],\n",
      "        [2., 2.],\n",
      "        [4., 2.],\n",
      "        [0., 0.],\n",
      "        [3., 1.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "tensor([[3., 2.],\n",
      "        [3., 2.],\n",
      "        [4., 2.],\n",
      "        [1., 2.],\n",
      "        [4., 2.],\n",
      "        [1., 2.],\n",
      "        [3., 3.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 2.],\n",
      "        [2., 1.],\n",
      "        [2., 0.],\n",
      "        [2., 1.],\n",
      "        [4., 2.],\n",
      "        [2., 2.]], device='cuda:0')\n",
      "tensor([[1., 1.],\n",
      "        [3., 1.],\n",
      "        [2., 0.],\n",
      "        [4., 2.],\n",
      "        [1., 1.],\n",
      "        [1., 3.],\n",
      "        [1., 1.],\n",
      "        [3., 1.],\n",
      "        [2., 0.],\n",
      "        [0., 1.],\n",
      "        [4., 1.],\n",
      "        [3., 1.],\n",
      "        [3., 2.],\n",
      "        [2., 0.],\n",
      "        [3., 1.],\n",
      "        [2., 1.]], device='cuda:0')\n",
      "tensor([[4., 1.],\n",
      "        [3., 2.],\n",
      "        [4., 2.],\n",
      "        [4., 2.],\n",
      "        [2., 1.],\n",
      "        [0., 3.],\n",
      "        [4., 1.],\n",
      "        [2., 2.],\n",
      "        [3., 2.],\n",
      "        [3., 2.],\n",
      "        [2., 2.],\n",
      "        [0., 2.],\n",
      "        [4., 2.],\n",
      "        [0., 2.],\n",
      "        [4., 1.],\n",
      "        [1., 2.]], device='cuda:0')\n",
      "tensor([[4., 1.],\n",
      "        [3., 4.],\n",
      "        [2., 2.],\n",
      "        [0., 1.],\n",
      "        [2., 3.],\n",
      "        [1., 0.],\n",
      "        [3., 1.],\n",
      "        [0., 1.],\n",
      "        [3., 2.],\n",
      "        [0., 1.],\n",
      "        [2., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [4., 0.],\n",
      "        [2., 1.]], device='cuda:0')\n",
      "tensor([[3., 2.],\n",
      "        [3., 0.],\n",
      "        [4., 1.],\n",
      "        [3., 1.],\n",
      "        [2., 1.],\n",
      "        [1., 1.],\n",
      "        [5., 2.],\n",
      "        [3., 1.],\n",
      "        [0., 0.],\n",
      "        [2., 2.],\n",
      "        [2., 2.],\n",
      "        [0., 0.],\n",
      "        [1., 1.],\n",
      "        [2., 4.],\n",
      "        [3., 2.],\n",
      "        [2., 1.]], device='cuda:0')\n",
      "tensor([[5., 2.],\n",
      "        [0., 0.],\n",
      "        [2., 4.],\n",
      "        [0., 1.],\n",
      "        [2., 3.],\n",
      "        [2., 1.],\n",
      "        [3., 2.],\n",
      "        [5., 2.],\n",
      "        [0., 0.],\n",
      "        [1., 1.],\n",
      "        [3., 2.],\n",
      "        [3., 0.],\n",
      "        [4., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [2., 0.]], device='cuda:0')\n",
      "tensor([[6., 0.],\n",
      "        [1., 2.],\n",
      "        [4., 2.],\n",
      "        [4., 0.],\n",
      "        [0., 1.],\n",
      "        [3., 2.],\n",
      "        [4., 1.],\n",
      "        [3., 1.],\n",
      "        [4., 2.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [4., 2.],\n",
      "        [2., 0.],\n",
      "        [4., 2.],\n",
      "        [3., 0.],\n",
      "        [1., 0.]], device='cuda:0')\n",
      "tensor([[0., 0.],\n",
      "        [0., 2.],\n",
      "        [1., 5.],\n",
      "        [4., 3.],\n",
      "        [4., 2.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [3., 0.],\n",
      "        [2., 2.],\n",
      "        [2., 0.],\n",
      "        [2., 2.],\n",
      "        [3., 3.],\n",
      "        [3., 1.],\n",
      "        [2., 1.],\n",
      "        [2., 0.],\n",
      "        [2., 2.]], device='cuda:0')\n",
      "tensor([[2., 2.],\n",
      "        [2., 2.],\n",
      "        [3., 1.],\n",
      "        [1., 0.],\n",
      "        [4., 2.],\n",
      "        [2., 1.],\n",
      "        [3., 2.],\n",
      "        [2., 3.],\n",
      "        [0., 1.],\n",
      "        [3., 1.],\n",
      "        [0., 1.],\n",
      "        [3., 0.],\n",
      "        [4., 2.],\n",
      "        [2., 2.],\n",
      "        [1., 2.],\n",
      "        [0., 1.]], device='cuda:0')\n",
      "tensor([[3., 1.],\n",
      "        [1., 0.],\n",
      "        [2., 0.],\n",
      "        [2., 0.],\n",
      "        [1., 3.],\n",
      "        [3., 1.],\n",
      "        [2., 3.],\n",
      "        [3., 2.],\n",
      "        [1., 2.],\n",
      "        [4., 2.],\n",
      "        [3., 1.],\n",
      "        [2., 2.],\n",
      "        [3., 0.],\n",
      "        [2., 2.],\n",
      "        [0., 0.],\n",
      "        [0., 1.]], device='cuda:0')\n",
      "tensor([[2., 1.],\n",
      "        [0., 2.],\n",
      "        [2., 2.],\n",
      "        [4., 1.],\n",
      "        [2., 2.],\n",
      "        [4., 3.],\n",
      "        [1., 1.],\n",
      "        [4., 1.],\n",
      "        [4., 2.],\n",
      "        [5., 0.],\n",
      "        [3., 2.],\n",
      "        [4., 2.],\n",
      "        [0., 0.],\n",
      "        [4., 1.],\n",
      "        [2., 0.],\n",
      "        [3., 0.]], device='cuda:0')\n",
      "tensor([[1., 1.],\n",
      "        [3., 1.],\n",
      "        [3., 2.],\n",
      "        [1., 1.],\n",
      "        [4., 0.],\n",
      "        [2., 0.],\n",
      "        [1., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 2.],\n",
      "        [2., 2.],\n",
      "        [3., 2.],\n",
      "        [0., 1.],\n",
      "        [3., 1.],\n",
      "        [3., 0.],\n",
      "        [3., 2.],\n",
      "        [1., 3.]], device='cuda:0')\n",
      "tensor([[1., 0.],\n",
      "        [1., 3.],\n",
      "        [0., 3.],\n",
      "        [3., 2.],\n",
      "        [0., 2.],\n",
      "        [0., 1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for data, targets in test_loader:\n",
    "        data = data.to(device).unsqueeze(1)\n",
    "\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        #test_spk, _ = net(data.view(data.size(0), -1))\n",
    "        test_spk, _ = model(data)\n",
    "        print(test_spk.sum(dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNN_maccs\n",
      "Accuracy:  0.915 ± 0.024\n",
      "AUC ROC: 0.906 ± 0.033\n",
      "Sensitivity: 0.745 ± 0.097\n",
      "Specificity: 0.947 ± 0.020\n"
     ]
    }
   ],
   "source": [
    "metrics_np = np.zeros(12)\n",
    "\n",
    "for i, metric in enumerate(results):\n",
    "    metrics_np[i*2] = np.round(np.mean(metric), 3)\n",
    "    metrics_np[i*2+1] = np.round(np.std(metric), 3)\n",
    "\n",
    "# Print Results\n",
    "if repr_type == \"fp\":\n",
    "    if mix:\n",
    "        print(f\"{net_type}_{fp_type}_morgan\")\n",
    "    else:\n",
    "        print(f\"{net_type}_{fp_type}\")\n",
    "else:\n",
    "    if mix:\n",
    "        print(f\"{net_type}_desc\")\n",
    "\n",
    "\n",
    "print(f\"Accuracy:  {metrics_np[0]:.3f} ± {metrics_np[1]:.3f}\")\n",
    "print(f\"AUC ROC: {metrics_np[2]:.3f} ± {metrics_np[3]:.3f}\")\n",
    "print(f\"Sensitivity: {metrics_np[4]:.3f} ± {metrics_np[5]:.3f}\")\n",
    "print(f\"Specificity: {metrics_np[6]:.3f} ± {metrics_np[7]:.3f}\")\n",
    "\n",
    "\n",
    "metric_names = ['Acc', 'AUC', 'Sn', 'Sp', 'F1', 'Precision']\n",
    "metrics_np = metrics_np.reshape(1, -1)\n",
    "columns = []\n",
    "for name in metric_names:\n",
    "    columns.extend([f'Mean {name}', f'Std {name}'])\n",
    "\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics_np, columns=columns)\n",
    "num_hidden = net_config['num_hidden']\n",
    "time_steps = train_config['num_steps']\n",
    "num_epochs = train_config['num_epochs']\n",
    "\n",
    "df_raw = pd.DataFrame({name: results[i] for i, name in enumerate(metric_names)})\n",
    "df_raw[\"Seed\"] = list(range(1, 31))\n",
    "df_raw = df_raw[[\"Seed\"] + metric_names]  # reorder columns\n",
    "\n",
    "blank = pd.DataFrame([[\"\"] * 12] * 3, columns=columns) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_2\\tox21\\SR-ARE_SNN_beta-0.95_maccs_167_l11024_t10_e100_b16_lr0.0001_count_loss_Adam_wd0_bias_scores.scv\n"
     ]
    }
   ],
   "source": [
    "save = True\n",
    "filename = make_filename(dirname, target_name, net_type, data_config, lr, weight_decay, optim_type, net_config, train_config, model)\n",
    "save = not flag\n",
    "\n",
    "filename = filename.replace(\"results\", \"final_results\")\n",
    "if calculate_scores:\n",
    "    filename = filename.replace(\".csv\", \"_scores.scv\")\n",
    "else:\n",
    "    filename = filename.replace(\".csv\", \"_no_scores.scv\")\n",
    "if save: \n",
    "    df_metrics.to_csv(filename, index=False)\n",
    "    blank.to_csv(filename, mode='a', index=False, header=False)\n",
    "    df_raw.to_csv(filename, mode='a', index=False)\n",
    "\n",
    "print(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
