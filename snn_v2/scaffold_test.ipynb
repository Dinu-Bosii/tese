{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "No normalization for NumAmideBonds. Feature removed!\n",
      "No normalization for NumAtomStereoCenters. Feature removed!\n",
      "No normalization for NumBridgeheadAtoms. Feature removed!\n",
      "No normalization for NumHeterocycles. Feature removed!\n",
      "No normalization for NumSpiroAtoms. Feature removed!\n",
      "No normalization for NumUnspecifiedAtomStereoCenters. Feature removed!\n",
      "No normalization for Phi. Feature removed!\n",
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (c:\\Users\\knsve\\Desktop\\MEI\\Tese\\torch\\snn_venv\\lib\\site-packages\\deepchem\\models\\torch_models\\__init__.py)\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (c:\\Users\\knsve\\Desktop\\MEI\\Tese\\torch\\snn_venv\\lib\\site-packages\\deepchem\\models\\torch_models\\__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "Skipped loading some PyTorch models, missing a dependency. No module named 'tensorflow'\n",
      "c:\\Users\\knsve\\Desktop\\MEI\\Tese\\torch\\snn_venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from rdkit import Chem\n",
    "from snn_model import get_loss_fn\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import load_dataset_df, smile_to_fp,smiles_to_descriptor,smiles_to_onehot, smiles_to_onehot_selfies, data_splitter, get_spiking_net, make_filename\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, f1_score, precision_score\n",
    "from csnn_model import get_prediction_fn\n",
    "from torch.utils.data import random_split, TensorDataset\n",
    "import torch.nn as nn\n",
    "import deepchem as dc\n",
    "from deepchem.splits.splitters import ScaffoldSplitter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/scikit-fingerprints/scikit-fingerprints.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip freeze\n",
    "#!pip install networkx==3.4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hepatobiliary disorders 1427 0.52\n",
      "Metabolism and nutrition disorders 1427 0.7\n",
      "Product issues 1427 0.02\n",
      "Eye disorders 1427 0.61\n",
      "Investigations 1427 0.81\n",
      "Musculoskeletal and connective tissue disorders 1427 0.7\n",
      "Gastrointestinal disorders 1427 0.91\n",
      "Social circumstances 1427 0.18\n",
      "Immune system disorders 1427 0.72\n",
      "Reproductive system and breast disorders 1427 0.51\n",
      "Neoplasms benign, malignant and unspecified (incl cysts and polyps) 1427 0.26\n",
      "General disorders and administration site conditions 1427 0.91\n",
      "Endocrine disorders 1427 0.23\n",
      "Surgical and medical procedures 1427 0.15\n",
      "Vascular disorders 1427 0.78\n",
      "Blood and lymphatic system disorders 1427 0.62\n",
      "Skin and subcutaneous tissue disorders 1427 0.92\n",
      "Congenital, familial and genetic disorders 1427 0.18\n",
      "Infections and infestations 1427 0.7\n",
      "Respiratory, thoracic and mediastinal disorders 1427 0.74\n",
      "Psychiatric disorders 1427 0.71\n",
      "Renal and urinary disorders 1427 0.64\n",
      "Pregnancy, puerperium and perinatal conditions 1427 0.09\n",
      "Ear and labyrinth disorders 1427 0.46\n",
      "Cardiac disorders 1427 0.69\n",
      "Nervous system disorders 1427 0.91\n",
      "Injury, poisoning and procedural complications 1427 0.66\n"
     ]
    }
   ],
   "source": [
    "files = ['tox21.csv','sider.csv', 'BBBP.csv']\n",
    "dt_file = files[1]\n",
    "dirname = dt_file.removesuffix('.csv')\n",
    "\n",
    "df, targets = load_dataset_df(filename=dt_file)\n",
    "\n",
    "for t in targets:\n",
    "    df_temp = df[[t, 'smiles']].dropna()\n",
    "    class_counts = df[t].count()\n",
    "    class_sum = df[t].sum()\n",
    "    print(t, class_counts, round(class_sum/class_counts, 2)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dirname == 'tox21':\n",
    "    # SR-ARE\n",
    "    target_name = targets[7]\n",
    "    # SR-MMP\n",
    "elif dirname == 'sider':\n",
    "    #Hepatobiliary disorders 1427 samples, 0.52 class ratio\n",
    "    target_name = targets[0]\n",
    "else:\n",
    "    target_name = targets[0]\n",
    "    \n",
    "df = df[[target_name, 'smiles']].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Molecular Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = [\"fp\", \"descriptor\", \"SELFIES-1hot\", \"SMILES-1hot\"]#, \"graph-list\"]\n",
    "\n",
    "repr_type = representations[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descriptor\n"
     ]
    }
   ],
   "source": [
    "if repr_type == \"fp\":\n",
    "    fp_types = [['morgan', 1024], ['maccs', 167], ['RDKit', 1024], ['count_morgan', 1024], ['pubchem', 881]]\n",
    "    mix = False\n",
    "    fp_type, num_bits = fp_types[1]\n",
    "    if mix and fp_type == 'RDKit':\n",
    "        num_bits = 512\n",
    "    data_config = {\"fp_type\": fp_type,\n",
    "                \"num_bits\": num_bits,\n",
    "                \"radius\": 2,\n",
    "                \"fp_type_2\": fp_types[0][0],\n",
    "                \"num_bits_2\": 1024 - num_bits,\n",
    "                \"mix\": mix,}\n",
    "    dim_2 = False\n",
    "    print(fp_type, '-', num_bits)\n",
    "    if mix: print(data_config['fp_type_2'], '-', data_config['num_bits_2'])\n",
    "    if dim_2: print(\"2D FP\")\n",
    "\n",
    "elif repr_type == \"descriptor\":\n",
    "    desc_type = [\"RDKit\", \"Mordred\"]\n",
    "    data_config = {\"desc_type\": desc_type[1],\n",
    "                   \"size\": 0,\n",
    "                }\n",
    "elif repr_type == \"SELFIES-1hot\":\n",
    "    dim_2 = True\n",
    "    data_config = {}\n",
    "\n",
    "elif repr_type == \"SMILES-1hot\":\n",
    "    dim_2 = True\n",
    "    data_config = {}\n",
    "\n",
    "data_config[\"repr_type\"] = repr_type\n",
    "print(repr_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:59:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:59:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:59:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:59:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:59:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:59:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:59:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:59:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:59:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:59:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:59:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:59:55] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:59:55] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m split \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaffold\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dirname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBBBP\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m feat_tensor, target_tensor, feat_df \u001b[38;5;241m=\u001b[39m \u001b[43msmiles_to_feat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrepr_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepr_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m dataset \u001b[38;5;241m=\u001b[39m TensorDataset(feat_tensor, target_tensor)\n",
      "File \u001b[1;32mc:\\Users\\knsve\\Desktop\\MEI\\Tese\\torch\\src\\snn_v2\\utils.py:47\u001b[0m, in \u001b[0;36msmiles_to_feat\u001b[1;34m(df, repr_type, data_config, target_name, dtype)\u001b[0m\n\u001b[0;32m     44\u001b[0m         feat_tensor \u001b[38;5;241m=\u001b[39m feat_tensor\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m repr_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescriptor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 47\u001b[0m     feat_df, desc_array, target_array \u001b[38;5;241m=\u001b[39m \u001b[43msmiles_to_desc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     feat_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(desc_array, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m     51\u001b[0m target_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(target_array, dtype\u001b[38;5;241m=\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mlong()\n",
      "File \u001b[1;32mc:\\Users\\knsve\\Desktop\\MEI\\Tese\\torch\\src\\snn_v2\\utils.py:182\u001b[0m, in \u001b[0;36msmiles_to_desc\u001b[1;34m(df, data_config, target_name, missing_val)\u001b[0m\n\u001b[0;32m    178\u001b[0m     feat_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((num_rows, array_size))\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m valid_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m--> 182\u001b[0m         mol_desc \u001b[38;5;241m=\u001b[39m \u001b[43mget_rdkit_desc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msmiles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m         feat_array[idx]\u001b[38;5;241m=\u001b[39m mol_desc\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m data_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesc_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMordred\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\knsve\\Desktop\\MEI\\Tese\\torch\\src\\snn_v2\\utils.py:157\u001b[0m, in \u001b[0;36mget_rdkit_desc\u001b[1;34m(smiles, array_size, missing_val)\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in descriptor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msmiles\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    156\u001b[0m         val \u001b[38;5;241m=\u001b[39m missing_val\n\u001b[1;32m--> 157\u001b[0m     \u001b[43mmol_desc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m val\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mol_desc\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "from utils import smiles_to_feat\n",
    "dtype = torch.float\n",
    "split = \"scaffold\" if dirname == \"BBBP\" else \"random\"\n",
    "dataset = None\n",
    "\n",
    "\n",
    "feat_tensor, target_tensor, feat_df = smiles_to_feat(df,repr_type=repr_type, data_config=data_config, target_name=target_name, dtype=dtype)\n",
    "\n",
    "dataset = TensorDataset(feat_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:00:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:00:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:00:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:00:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:00:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:00:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:00:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:00:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:00:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:00:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:00:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:00:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:00:56] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DiskDataset X.shape: (1141,), y.shape: (1141,), w.shape: (1141,), task_names: [0]>\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "smiles_list = df[\"smiles\"].tolist()\n",
    "labels = df[target_name].values\n",
    "\n",
    "Xs = np.zeros(len(smiles_list))\n",
    "weights = np.zeros(len(smiles_list))\n",
    "\n",
    "# Create a DiskDataset\n",
    "dataset = dc.data.DiskDataset.from_numpy(X=Xs, y=labels, w=weights, ids=smiles_list)\n",
    "\n",
    "scaffold_splitter = ScaffoldSplitter()\n",
    "#by default is 0.8 0.1 0.1\n",
    "#print(\"scaffold splitting..\")\n",
    "train, val,  test = scaffold_splitter.train_valid_test_split(dataset, seed=seed)\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C(CNCCNCCNCCN)N' 'Cl[Tl]' 'C[N+](C)(C)CC(CC(=O)O)O' ...\n",
      " 'C1CN(CCN1CCC2=C(C=C3C(=C2)CC(=O)N3)Cl)C4=NSC5=CC=CC=C54.O.Cl'\n",
      " 'C1=CC(=CC=C1CCC2=CNC3=C2C(=O)N=C(N3)N)C(=O)N[C@H](CCC(=O)O)C(=O)O'\n",
      " 'C[N+]1(CCC(C1)OC(=O)C(C2CCCC2)(C3=CC=CC=C3)O)C']\n"
     ]
    }
   ],
   "source": [
    "print(train.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ids_df = pd.DataFrame({'smiles': train.ids, target_name: train.y})\n",
    "val_ids_df = pd.DataFrame({'smiles': val.ids, target_name: val.y})\n",
    "test_ids_df = pd.DataFrame({'smiles': test.ids, target_name: test.y})\n",
    "#print(len(train_ids_df), len(val_ids_df), len(test_ids_df))\n",
    "#print(\"featurizing..\")\n",
    "fp_train, target_train = smile_to_fp(df=train_ids_df, data_config=data_config, target_name=target_name)\n",
    "fp_val, target_val = smile_to_fp(df=val_ids_df, data_config=data_config, target_name=target_name)\n",
    "fp_test, target_test = smile_to_fp(df=test_ids_df, data_config=data_config, target_name=target_name)\n",
    "\n",
    "fp_train_tensor = torch.tensor(fp_train, dtype=dtype)\n",
    "target_train_tensor = torch.tensor(target_train, dtype=dtype).long()\n",
    "fp_val_tensor = torch.tensor(fp_val, dtype=dtype)\n",
    "target_val_tensor = torch.tensor(target_val, dtype=dtype).long()\n",
    "fp_test_tensor = torch.tensor(fp_test, dtype=dtype)\n",
    "target_test_tensor = torch.tensor(target_test, dtype=dtype).long()\n",
    "\n",
    "\n",
    "train = TensorDataset(fp_train_tensor, target_train_tensor)\n",
    "val = TensorDataset(fp_val_tensor, target_val_tensor)\n",
    "test = TensorDataset(fp_test_tensor, target_test_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
