{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from rdkit import Chem\n",
    "from snn_model import get_loss_fn\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import load_dataset_df, smile_to_fp,smiles_to_descriptor,smiles_to_onehot, smiles_to_onehot_selfies, data_splitter, get_spiking_net, make_filename\n",
    "from utils import smiles_to_feat\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, f1_score, precision_score\n",
    "from csnn_model import get_prediction_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/scikit-fingerprints/scikit-fingerprints.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip freeze\n",
    "#!pip install networkx==3.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_path = f\"./results/logs/output_{timestamp}.txt\"\n",
    "log_file = open(log_path, \"w\")\n",
    "sys.stdout = log_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['tox21.csv','sider.csv', 'BBBP.csv']\n",
    "dt_file = files[1]\n",
    "dirname = dt_file.removesuffix('.csv')\n",
    "\n",
    "df, targets = load_dataset_df(filename=dt_file)\n",
    "\n",
    "for t in targets:\n",
    "    df_temp = df[[t, 'smiles']].dropna()\n",
    "    class_counts = df[t].count()\n",
    "    class_sum = df[t].sum()\n",
    "    print(t, class_counts, round(class_sum/class_counts, 2)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dirname == 'tox21':\n",
    "    # SR-ARE\n",
    "    target_name = targets[7]\n",
    "    # SR-MMP\n",
    "elif dirname == 'sider':\n",
    "    #Hepatobiliary disorders 1427 samples, 0.52 class ratio\n",
    "    target_name = targets[0]\n",
    "else:\n",
    "    target_name = targets[0]\n",
    "    \n",
    "df = df[[target_name, 'smiles']].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Molecular Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = [\"fp\", \"descriptor\", \"SELFIES-1hot\", \"SMILES-1hot\"]#, \"graph-list\"]\n",
    "\n",
    "repr_type = representations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if repr_type == \"fp\":\n",
    "    fp_types = [['morgan', 1024], ['maccs', 167], ['RDKit', 1024], ['count_morgan', 1024], ['pubchem', 881]]\n",
    "    mix = False\n",
    "    fp_type, num_bits = fp_types[0]\n",
    "    if mix and fp_type == 'RDKit':\n",
    "        num_bits = 512\n",
    "    data_config = {\"fp_type\": fp_type,\n",
    "                \"num_bits\": num_bits,\n",
    "                \"radius\": 2,\n",
    "                \"fp_type_2\": fp_types[0][0],\n",
    "                \"num_bits_2\": 1024 - num_bits,\n",
    "                \"mix\": mix,\n",
    "                \"dim_2\": True}\n",
    "    dim_2 = data_config['dim_2']\n",
    "    print(fp_type, '-', num_bits)\n",
    "    if mix: print(data_config['fp_type_2'], '-', data_config['num_bits_2'])\n",
    "    if dim_2: print(\"2D FP\")\n",
    "\n",
    "elif repr_type == \"descriptor\":\n",
    "    desc_type = [\"RDKit\", \"Mordred\"]\n",
    "    data_config = {\"desc_type\": desc_type[0],\n",
    "                   \"size\": 0,\n",
    "                }\n",
    "\n",
    "data_config[\"repr_type\"] = repr_type\n",
    "print(repr_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "split = \"scaffold\" if dirname == \"BBBP\" else \"random\"\n",
    "dataset = None\n",
    "\n",
    "\n",
    "feat_tensor, target_tensor, feat_df = smiles_to_feat(df,repr_type=repr_type, data_config=data_config, target_name=target_name, dtype=dtype)\n",
    "print(feat_tensor.shape)\n",
    "dataset = TensorDataset(feat_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "loss_types = ['ce_mem', 'rate_loss', 'count_loss', 'temporal_loss']\n",
    "loss_type = loss_types[2]\n",
    "print(loss_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_types = [\"SNN\", \"DSNN\", \"CSNN\", \"RSNN\"]\n",
    "net_type = net_types[2]\n",
    "slope = 10\n",
    "#spike_grad = surrogate.fast_sigmoid(slope=slope)\n",
    "spike_grad = None\n",
    "beta = 0.95\n",
    "bias = True\n",
    "net_config = {\n",
    "            \"num_hidden\": 1024,\n",
    "            \"num_hidden_l2\": 256,\n",
    "            \"num_steps\": 100,\n",
    "            \"spike_grad\": spike_grad,\n",
    "            \"slope\": None if not spike_grad else slope, #spike_grad.__closure__[0].cell_contents,\n",
    "            \"beta\": beta,\n",
    "            \"encoding\": 'rate' if loss_type != 'temporal_loss' else 'ttfs',\n",
    "            \"bias\": bias,\n",
    "            \"out_num\": 2,\n",
    "            \"num_hidden_layers\": 2,\n",
    "            \"num_hidden_l3\": 256,\n",
    "            }\n",
    "if net_type == \"CSNN\":\n",
    "    \"\"\"     \n",
    "    net_config['num_conv'] = 1\n",
    "    net_config[\"pool_size\"] = 4\n",
    "    net_config[\"conv_kernel\"] = 5\n",
    "    net_config[\"conv_stride\"] = [1 for _ in range(net_config['num_conv'])]\n",
    "    net_config[\"conv_groups\"] = 1 \"\"\"\n",
    "    net_config['num_conv'] = 1\n",
    "    net_config[\"pool_size\"] = 2\n",
    "    net_config[\"conv_kernel\"] = 3\n",
    "    net_config[\"conv_stride\"] = [1 for _ in range(net_config['num_conv'])]\n",
    "    net_config[\"conv_groups\"] = 1\n",
    "\n",
    "if repr_type == \"fp\":\n",
    "    net_config[\"input_size\"] = 1024 if data_config['mix'] else num_bits\n",
    "    net_config[\"2d\"] = data_config['dim_2']\n",
    "\n",
    "elif repr_type == \"descriptor\":\n",
    "    net_config[\"input_size\"] = feat_tensor.shape[1]\n",
    "    net_config[\"2d\"] = False\n",
    "    #net_config[\"num_steps\"] = 10\n",
    "\n",
    "print(net_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "pop_coding = net_config['out_num'] > 2\n",
    "lr=1e-4 #1e-6 default for 1000 epochs. csnn requires higher\n",
    "iterations = 30\n",
    "weight_decay = 0 # 1e-5\n",
    "#weight_decay = 1e-4\n",
    "optim_type = 'Adam'\n",
    "#optim_type = 'SGD'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "batch_size = 16 #16, 8\n",
    "scores = True\n",
    "train_config = {\"num_epochs\": 100,\n",
    "                \"batch_size\": batch_size,\n",
    "                \"device\": device,\n",
    "                \"loss_type\": loss_type,\n",
    "                \"loss_fn\": None,\n",
    "                'dtype': dtype,\n",
    "                'num_steps': net_config['num_steps'],\n",
    "                'val_net': None,\n",
    "                'prediction_fn': get_prediction_fn(encoding=net_config['encoding'], pop_coding=pop_coding, scores=scores),\n",
    "                }\n",
    "drop_last = net_type == \"CSNN\"\n",
    "pin_memory = device == \"cuda\"\n",
    "save_csv = True\n",
    "save_models = True\n",
    "results = [[], [], [], [], [], []]\n",
    "print(train_config[\"prediction_fn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----Configuration-----\")\n",
    "print(data_config)\n",
    "print(net_config)\n",
    "print(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import RDLogger\n",
    "\n",
    "# Disable RDKit logging for the scaffold meeting\n",
    "RDLogger.DisableLog('rdApp.*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(metrics_list, all_targets, all_preds):\n",
    "    auc_roc = roc_auc_score(all_targets, all_preds)\n",
    "    \n",
    "    all_preds = np.array(all_preds) >= 0.0\n",
    "    accuracy = accuracy_score(all_targets, all_preds)\n",
    "    tn, fp, fn, tp = confusion_matrix(all_targets, all_preds).ravel()\n",
    "    sensitivity = tp/(tp + fn)\n",
    "    specificity = tn/(tn + fp)\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "    precision = precision_score(all_targets, all_preds)\n",
    "    \n",
    "    metrics_list[0].append(accuracy)\n",
    "    metrics_list[1].append(auc_roc)\n",
    "    metrics_list[2].append(sensitivity)\n",
    "    metrics_list[3].append(specificity)\n",
    "    metrics_list[4].append(f1)\n",
    "    metrics_list[5].append(precision)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_norm(train_subset, val_subset, test_subset):\n",
    "    train_tensor, _ = train_subset[:]\n",
    "    val_tensor, _ = val_subset[:]\n",
    "    test_tensor, _ = test_subset[:]\n",
    "\n",
    "    mean = train_tensor.mean(dim=0)\n",
    "    std = train_tensor.std(dim=0)\n",
    "    std = std.clamp(min=1e-6)\n",
    "    train_norm = (train_tensor - mean)\n",
    "\n",
    "    train_norm = train_norm / std\n",
    "    val_norm = (val_tensor - mean) / std\n",
    "    test_norm = (test_tensor - mean) / std\n",
    "\n",
    "    return train_norm, val_norm, test_norm\n",
    "\n",
    "def minmax_norm(train_subset, val_subset, test_subset):\n",
    "    train_tensor, _ = train_subset[:]\n",
    "    val_tensor, _ = val_subset[:]\n",
    "    test_tensor, _ = test_subset[:]\n",
    "\n",
    "    min_val = train_tensor.min(dim=0).values\n",
    "    max_val = train_tensor.max(dim=0).values\n",
    "    range_val = (max_val - min_val).clamp(min=1e-6)\n",
    "\n",
    "    train_norm = ((train_tensor - min_val) / range_val).clamp(0.0, 1.0)\n",
    "    val_norm   = ((val_tensor   - min_val) / range_val).clamp(0.0, 1.0)\n",
    "    test_norm  = ((test_tensor  - min_val) / range_val).clamp(0.0, 1.0)\n",
    "\n",
    "    return train_norm, val_norm, test_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_in_train = False\n",
    "print(\"Validation Set used in training:\", val_in_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(iterations):\n",
    "    print(f\"Iteration:{iter + 1}/{iterations}\")\n",
    "    seed = iter + 1\n",
    "    print(f\"Seed:{seed}\")\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    net, train_net, val_net, test_net = get_spiking_net(net_type, net_config)\n",
    "    net = net.to(device)\n",
    "    train_config['val_net'] = val_net\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=weight_decay)\n",
    "    train_config[\"scheduler\"] = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=train_config['num_epochs'], eta_min=1e-6)\n",
    "    \n",
    "    # DATA SPLIT\n",
    "    train, val, test = data_splitter(feat_df, target_name, split=split, dataset=dataset, data_config=data_config, seed=seed, dtype=dtype)\n",
    "    _, train_label = train[:]\n",
    "    _, val_label = val[:]\n",
    "    _, test_label = test[:]\n",
    "        \n",
    "    if repr_type == \"descriptor\":\n",
    "        train_data, val_data, test_data = minmax_norm(train, val, test)\n",
    "        train = TensorDataset(train_data, train_label)\n",
    "        val = TensorDataset(val_data,val_label)\n",
    "        test = TensorDataset(test_data, test_label)\n",
    "\n",
    "    if val_in_train:\n",
    "        train_feat, _ = train[:]\n",
    "        val_feat, _ = val[:]\n",
    "        train = TensorDataset(\n",
    "        torch.cat([train_feat, val_feat], dim=0),\n",
    "        torch.cat([train_label, val_label], dim=0)\n",
    "        )\n",
    "    \n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, pin_memory=pin_memory, drop_last=drop_last)\n",
    "    val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, pin_memory=pin_memory)\n",
    "    test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, pin_memory=pin_memory)\n",
    "\n",
    "    # LOSS FN\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.array([0, 1], dtype=np.int8), y=np.array(train_label, dtype=np.int8))\n",
    "\n",
    "    print(\"class weights:\", class_weights)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float, device=device)\n",
    "    train_config[\"loss_fn\"] = get_loss_fn(loss_type=loss_type, class_weights=class_weights, pop_coding=pop_coding)\n",
    "    train_config[\"test_loader\"] = test_loader\n",
    "\n",
    "    # TRAINING\n",
    "    start_time = time.time()\n",
    "    net, loss_hist, val_acc_hist, val_auc_hist, net_list, best_val_net = train_net(net=net, optimizer=optimizer, train_loader=train_loader, val_loader=val_loader, train_config=train_config, net_config=net_config)\n",
    "    end_time = time.time()\n",
    "    train_time = end_time - start_time\n",
    "    times.append(train_time)\n",
    "    print()\n",
    "    print(f\"Time: {train_time:.4f} seconds\")\n",
    "    # TESTING\n",
    "    all_preds_last, all_targets_last = test_net(net, device, test_loader, train_config)\n",
    "    auc_roc_test = roc_auc_score(all_targets_last, all_preds_last)\n",
    "    print('Last model AUC on test set:', auc_roc_test)\n",
    "    model = net\n",
    "    model.load_state_dict(best_val_net)\n",
    "    all_preds_best, all_targets_best = test_net(model, device, test_loader, train_config)\n",
    "    auc_roc_test = roc_auc_score(all_targets_best, all_preds_best)\n",
    "    print('Best model AUC on test set:', auc_roc_test)\n",
    "\n",
    "    if save_models:\n",
    "        filename = make_filename(dirname, target_name, net_type, data_config, lr, weight_decay, optim_type, net_config, train_config, model, model = True)\n",
    "        if scores:\n",
    "            model_name = filename.removesuffix('.csv') + f\"-scores-seed-{seed}\" +'.pth'\n",
    "        else:\n",
    "            model_name = filename.removesuffix('.csv') + f\"-no_scores-seed-{seed}\" +'.pth'\n",
    "        torch.save(best_val_net, model_name)\n",
    "\n",
    "    calc_metrics(results, all_preds=all_preds_best, all_targets=all_targets_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(times)/len(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smoothed Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.signal import savgol_filter\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "#from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "#print(loss_hist[len(loss_hist) - 5:len(loss_hist)])\n",
    "\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "#plt.plot(np.convolve(loss_hist, np.ones(30)/30, mode='valid'))\n",
    "#plt.plot(savgol_filter(loss_hist, window_length=100, polyorder=3))\n",
    "#plt.plot(lowess(loss_hist, np.arange(len(loss_hist)), frac=0.1)[:, 1])\n",
    "plt.plot(gaussian_filter1d(loss_hist, sigma=6))\n",
    "#plt.plot(loss_hist)\n",
    "#plt.axhline(y=1, color='r', linestyle='--', label='y = 1')\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = train_config['num_epochs']\n",
    "num_minibatches_per_epoch = len(loss_hist) // num_epochs\n",
    "\n",
    "# Create x-axis values in terms of epochs\n",
    "epochs = np.linspace(1, num_epochs, len(loss_hist))\n",
    "epoch_losses = np.array(loss_hist).reshape(num_epochs, num_minibatches_per_epoch).mean(axis=1)\n",
    "\n",
    "plt.plot(range(1, num_epochs + 1), epoch_losses, label=\"Loss per Epoch\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Set\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "\n",
    "#plt.plot(gaussian_filter1d(val_auc_hist, sigma=6))\n",
    "plt.plot(val_auc_hist)\n",
    "plt.title(\"ROC AUC on Validation Set\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"ROC-AUC\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_np = np.zeros(12)\n",
    "\n",
    "for i, metric in enumerate(results):\n",
    "    metrics_np[i*2] = np.round(np.mean(metric), 3)\n",
    "    metrics_np[i*2+1] = np.round(np.std(metric), 3)\n",
    "\n",
    "# Print Results\n",
    "print(f\"Accuracy:  {metrics_np[0]:.3f} ± {metrics_np[1]:.3f}\")\n",
    "print(f\"AUC ROC: {metrics_np[2]:.3f} ± {metrics_np[3]:.3f}\")\n",
    "print(f\"Sensitivity: {metrics_np[4]:.3f} ± {metrics_np[5]:.3f}\")\n",
    "print(f\"Specificity: {metrics_np[6]:.3f} ± {metrics_np[7]:.3f}\")\n",
    "\n",
    "metric_names = ['Acc', 'AUC', 'Sn', 'Sp', 'F1', 'Precision']\n",
    "metrics_np = metrics_np.reshape(1, -1)\n",
    "columns = []\n",
    "for name in metric_names:\n",
    "    columns.extend([f'Mean {name}', f'Std {name}'])\n",
    "\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics_np, columns=columns)\n",
    "num_hidden = net_config['num_hidden']\n",
    "time_steps = train_config['num_steps']\n",
    "num_epochs = train_config['num_epochs']\n",
    "\n",
    "# TODO: Add neuron thresholds to name\n",
    "filename = make_filename(dirname, target_name, net_type, data_config, lr, weight_decay, optim_type, net_config, train_config, model)\n",
    "if scores:\n",
    "    filename  = filename.removesuffix('.csv') + \"-scores.csv\"\n",
    "else:\n",
    "    filename  = filename.removesuffix('.csv') + \"-no_scores.csv\"\n",
    "\n",
    "if save_csv: df_metrics.to_csv(filename, index=False)\n",
    "\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_auc = np.argmin(results[1])\n",
    "print(\"min auc:\", results[1][min_auc], \"at\", min_auc)\n",
    "\n",
    "max_auc = np.argmax(results[1])\n",
    "print(\"max auc:\", results[1][max_auc], \"at\", max_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
